{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/optimum-neuron.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1678a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance-type: trn1.2xlarge\n",
      "instance-id: i-0570615e41700a481\n",
      "+--------+--------+--------+---------+\n",
      "| NEURON | NEURON | NEURON |   PCI   |\n",
      "| DEVICE | CORES  | MEMORY |   BDF   |\n",
      "+--------+--------+--------+---------+\n",
      "| 0      | 2      | 32 GB  | 00:1e.0 |\n",
      "+--------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "!neuron-ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17851024",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358933de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c)\n",
      "100%|██████████| 2/2 [00:00<00:00, 130.36it/s]\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c/cache-084cb9babe899b20.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/ff44c4421d7e70aa810b0fa79d36908a38b87aff8125d002cd44f7fcd31f493c/cache-5f7f794fe0ef7b57.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10003\n",
      "Test dataset size: 3080\n",
      "{'text': 'Can I change my address?', 'label': 30}\n",
      "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset id from huggingface.co/dataset\n",
    "dataset_id = \"banking77\"\n",
    "# Model id to load the tokenizer\n",
    "model_id = \"bert-base-uncased\"\n",
    "save_dataset_path = \"dataset\"\n",
    "\n",
    "\n",
    "# Load raw dataset\n",
    "raw_dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(raw_dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(raw_dataset['test'])}\")\n",
    "\n",
    "# Train dataset size: 10003\n",
    "# Test dataset size: 3080\n",
    "from random import randrange\n",
    "\n",
    "random_id = randrange(len(raw_dataset['train']))\n",
    "print(raw_dataset['train'][random_id])\n",
    "# {'text': 'How can I change my PIN without going to the bank?', 'label': 21}\n",
    "\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Tokenize helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize dataset\n",
    "raw_dataset =  raw_dataset.rename_column(\"label\", \"labels\") # to match Trainer\n",
    "tokenized_dataset = raw_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "print(tokenized_dataset[\"train\"].features.keys())\n",
    "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask','lable'])\n",
    "# save dataset to disk\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(save_dataset_path,\"train\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(save_dataset_path,\"eval\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3d70d49",
   "metadata": {},
   "source": [
    "## precompiple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b3283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-07 13:08:19.000831: INFO ||PARALLEL_COMPILE||: Removing existing workdir /tmp/parallel_compile_workdir\n",
      "2023-03-07 13:08:19.000858: INFO ||PARALLEL_COMPILE||: Running trial run (add option to terminate trial run early; also ignore trial run's generated outputs, i.e. loss, checkpoints)\n",
      "is precompilation: 1\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n",
      "  Number of trainable parameters = 335220813\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]2023-03-07 13:08:29.000438: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.398_16500088451374625205.hlo.pb \n",
      "2023-03-07 13:08:29.000439: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-07 13:08:29.000442: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16500088451374625205/MODULE_SyncTensorsGraph.398_16500088451374625205/d0c928c7-f0e5-448f-aa12-bb0b3c9f26ed/MODULE_SyncTensorsGraph.398_16500088451374625205.neff. Exiting with a successfully compiled graph\n",
      "  5%|▌         | 1/20 [00:00<00:06,  3.04it/s]2023-03-07 13:08:31.000732: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb \n",
      "2023-03-07 13:08:31.000733: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/4ba6a9ec-e217-432b-9289-25789e48e9d3/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-07 13:08:31.000733: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/c4e9face-567b-43a0-89b3-bd6543a107fa/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-07 13:08:31.000734: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/9040b2a7-72e3-45b0-bb8e-3993ef0b52c2/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff. Continuing with search.\n",
      "2023-03-07 13:08:31.000734: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-07 13:08:31.000735: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-07 13:08:31.000736: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_1_SyncTensorsGraph.41359_12643167559187961032_ip-172-31-79-164-6e4c064d-12169-5f64f13cdd0a8/554846e9-7d9a-4799-ade9-eb576d9e31e3/MODULE_1_SyncTensorsGraph.41359_12643167559187961032_ip-172-31-79-164-6e4c064d-12169-5f64f13cdd0a8.neff. Continuing with search.\n",
      "2023-03-07 13:08:31.000736: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-07 13:08:31.000739: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12643167559187961032/MODULE_SyncTensorsGraph.41359_12643167559187961032/3643ee85-d268-4110-9b6f-3334f79e456c\n",
      "2023-03-07 13:08:31.000783: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 10%|█         | 2/20 [00:04<00:51,  2.84s/it]2023-03-07 13:08:36.000444: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb \n",
      "2023-03-07 13:08:36.000456: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/458630af-6078-44c5-9f78-be6a11204178/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-07 13:08:36.000457: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/b18a241b-f191-4fdd-a61b-4faf146e9e76/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-07 13:08:36.000457: INFO ||NCC_WRAPPER||: neff size is zero with flags '--model-type=transformer'. NEFF: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/3f5ed472-c6a7-424e-bf1e-37a2ef1843fb/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff. Continuing with search.\n",
      "2023-03-07 13:08:36.000457: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-03-07 13:08:36.000463: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_17290973370322587611/MODULE_SyncTensorsGraph.41359_17290973370322587611/a55587ca-74ec-45c2-a363-cbbdc359bfa4\n",
      "2023-03-07 13:08:36.000467: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 55%|█████▌    | 11/20 [00:11<00:03,  2.98it/s]2023-03-07 13:08:42.000859: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.41359_12626849408468488449.hlo.pb \n",
      "2023-03-07 13:08:42.000980: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12626849408468488449/MODULE_SyncTensorsGraph.41359_12626849408468488449/30a0f8bb-6a4a-4d31-9455-4bee91142c6c/MODULE_SyncTensorsGraph.41359_12626849408468488449.neff. Exiting with a successfully compiled graph\n",
      "100%|██████████| 20/20 [00:17<00:00,  4.20it/s]***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n",
      "2023-03-07 13:08:47.000474: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.8831_6359244636338052065.hlo.pb \n",
      "2023-03-07 13:08:47.000532: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6359244636338052065/MODULE_SyncTensorsGraph.8831_6359244636338052065/9eb4a6a8-5bef-4d24-920a-9c232c447f1d/MODULE_SyncTensorsGraph.8831_6359244636338052065.neff. Exiting with a successfully compiled graph\n",
      "2023-03-07 13:08:47.000769: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_1002868706066901398.hlo.pb \n",
      "2023-03-07 13:08:47.000773: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_SyncTensorsGraph.4_1002868706066901398/8121fb1e-f175-4f7a-baaa-14a326a19083/MODULE_SyncTensorsGraph.4_1002868706066901398.neff. Exiting with a successfully compiled graph\n",
      "2023-03-07 13:08:47.000843: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_14019065114978382472.hlo.pb \n",
      "2023-03-07 13:08:47.000847: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_SyncTensorsGraph.4_14019065114978382472/5d49a674-a046-424b-9e79-b5d4db41e0d1/MODULE_SyncTensorsGraph.4_14019065114978382472.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 34.52it/s]\u001b[A\n",
      "                                               [A\n",
      "\u001b[A{'eval_loss': 7.651089615213501e-43, 'eval_f1': 0.0, 'eval_runtime': 1.1798, 'eval_samples_per_second': 8.476, 'eval_steps_per_second': 1.695, 'epoch': 1.0}\n",
      "100%|██████████| 20/20 [00:18<00:00,  4.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29.94it/s]\u001b[A\n",
      "                                               \u001b[ASaving model checkpoint to run1/checkpoint-20\n",
      "Configuration saved in run1/checkpoint-20/config.json\n",
      "Model weights saved in run1/checkpoint-20/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from run1/checkpoint-20 (score: 0.0).\n",
      "{'train_runtime': 28.7315, 'train_samples_per_second': 0.696, 'train_steps_per_second': 0.696, 'train_loss': 7.006492321624086e-47, 'epoch': 1.0}\n",
      "100%|██████████| 20/20 [00:28<00:00,  1.44s/it]\n",
      "tokenizer config file saved in run1/tokenizer_config.json\n",
      "Special tokens file saved in run1/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'dataset': {'name': 'banking77', 'type': 'banking77', 'config': 'default', 'split': 'test', 'args': 'default'}}\n",
      "2023-03-07 13:09:01.000356: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs\n",
      "2023-03-07 13:09:01.000358: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.neff\n",
      "2023-03-07 13:09:01.000359: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.neff\n",
      "..................................................Killed\n",
      "2023-03-07 13:17:06.000719: ERROR ||PARALLEL_COMPILE||: parallel compilation with neuronx-cc exited with error.Received error code: 137\n",
      "..........Killed\n",
      "2023-03-07 13:18:44.000114: ERROR ||PARALLEL_COMPILE||: parallel compilation with neuronx-cc exited with error.Received error code: 137\n",
      "2023-03-07 13:18:44.000115: ERROR ||PARALLEL_COMPILE||: Failed to compile graphs after 0 retries. Please check the graph.\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Compilation summary:\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_12643167559187961032.hlo.pb failed with 0 retries\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Compilation failed with error message: parallel compilation with neuronx-cc exited with error.Received error code: 137\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.41359_17290973370322587611.hlo.pb failed with 0 retries\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Compilation failed with error message: parallel compilation with neuronx-cc exited with error.Received error code: 137\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Total graphs: 2\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Total successful compilations: 0\n",
      "2023-03-07 13:18:44.000115: INFO ||PARALLEL_COMPILE||: Total failed compilations: 2\n"
     ]
    }
   ],
   "source": [
    "!neuron_parallel_compile python3 scripts/train.py --model_id bert-large-uncased --per_device_train_batch_size 8 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8dc0746",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae31815",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/train.py --model_id bert-large-uncased --per_device_train_batch_size 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b757305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
