{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30b397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Found existing installation: optimum-neuron 0.1.1.dev0\n",
      "Uninstalling optimum-neuron-0.1.1.dev0:\n",
      "  Successfully uninstalled optimum-neuron-0.1.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall optimum-neuron -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02eb0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.1.dev0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optimum.neuron \n",
    "\n",
    "optimum.neuron.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b53199e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.28.1\n",
      "- Platform: Linux-5.15.0-1030-aws-x86_64-with-glibc2.29\n",
      "- Python version: 3.8.10\n",
      "- Huggingface_hub version: 0.13.3\n",
      "- Safetensors version: not installed\n",
      "- PyTorch version (GPU?): 1.13.1+cu117 (False)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54868a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0,>=0.11.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.1)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.28.0\n",
      "    Uninstalling transformers-4.28.0:\n",
      "      Successfully uninstalled transformers-4.28.0\n",
      "Successfully installed transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f7fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting git+https://github.com/huggingface/optimum-neuron.git@fix_multiclass_training_issue\n",
      "  Cloning https://github.com/huggingface/optimum-neuron.git (to revision fix_multiclass_training_issue) to /tmp/pip-req-build-0s_1d2jo\n",
      "  Running command git clone -q https://github.com/huggingface/optimum-neuron.git /tmp/pip-req-build-0s_1d2jo\n",
      "  Running command git checkout -b fix_multiclass_training_issue --track origin/fix_multiclass_training_issue\n",
      "  Switched to a new branch 'fix_multiclass_training_issue'\n",
      "  Branch 'fix_multiclass_training_issue' set up to track remote branch 'fix_multiclass_training_issue' from 'origin'.\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: optimum@ git+https://github.com/huggingface/optimum.git from git+https://github.com/huggingface/optimum.git in /home/ubuntu/.local/lib/python3.8/site-packages (from optimum-neuron==0.1.1.dev0) (1.7.1)\n",
      "Requirement already satisfied: transformers>=4.28.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from optimum-neuron==0.1.1.dev0) (4.28.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (2.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (0.13.3)\n",
      "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.8/dist-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.13.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.20.3)\n",
      "Requirement already satisfied: coloredlogs in /home/ubuntu/.local/lib/python3.8/site-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.8/site-packages (from optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (3.9.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (3.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.5.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.8.0->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (11.7.99)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from coloredlogs->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.local/lib/python3.8/site-packages (from sympy->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers>=4.28.0->optimum-neuron==0.1.1.dev0) (2.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (19.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (45.2.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch>=1.9->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (0.34.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum@ git+https://github.com/huggingface/optimum.git->optimum-neuron==0.1.1.dev0) (1.14.0)\n",
      "Building wheels for collected packages: optimum-neuron\n",
      "  Building wheel for optimum-neuron (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for optimum-neuron: filename=optimum_neuron-0.1.1.dev0-py3-none-any.whl size=46158 sha256=9bbada22552e543b6dba6cbb86afe06f561e5330626ba3b4e087fd3f63b7ca93\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ap5hj3lp/wheels/09/10/ed/d2a649af5f731967cccec21534708609afd97c39f51f40079a\n",
      "Successfully built optimum-neuron\n",
      "Installing collected packages: optimum-neuron\n",
      "Successfully installed optimum-neuron-0.1.1.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/optimum-neuron.git@fix_multiclass_training_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1678a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "instance-type: trn1.2xlarge\n",
      "instance-id: i-0570615e41700a481\n",
      "+--------+--------+--------+---------+\n",
      "| NEURON | NEURON | NEURON |   PCI   |\n",
      "| DEVICE | CORES  | MEMORY |   BDF   |\n",
      "+--------+--------+--------+---------+\n",
      "| 0      | 2      | 32 GB  | 00:1e.0 |\n",
      "+--------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "!neuron-ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17851024",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358933de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n",
      "Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4)\n",
      "100%|██████████| 2/2 [00:00<00:00, 665.76it/s]\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-c98c758d88fafd27.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10003\n",
      "Test dataset size: 3080\n",
      "{'text': 'Which merchants accept this card?', 'label': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset id from huggingface.co/dataset\n",
    "dataset_id = \"banking77\"\n",
    "# Model id to load the tokenizer\n",
    "model_id = \"bert-base-uncased\"\n",
    "save_dataset_path = \"dataset\"\n",
    "\n",
    "\n",
    "# Load raw dataset\n",
    "raw_dataset = load_dataset(dataset_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(raw_dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(raw_dataset['test'])}\")\n",
    "\n",
    "# Train dataset size: 10003\n",
    "# Test dataset size: 3080\n",
    "from random import randrange\n",
    "\n",
    "random_id = randrange(len(raw_dataset['train']))\n",
    "print(raw_dataset['train'][random_id])\n",
    "# {'text': 'How can I change my PIN without going to the bank?', 'label': 21}\n",
    "\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Tokenize helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True,return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize dataset\n",
    "raw_dataset =  raw_dataset.rename_column(\"label\", \"labels\") # to match Trainer\n",
    "tokenized_dataset = raw_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "print(tokenized_dataset[\"train\"].features.keys())\n",
    "# dict_keys(['input_ids', 'token_type_ids', 'attention_mask','lable'])\n",
    "# save dataset to disk\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(save_dataset_path,\"train\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(save_dataset_path,\"eval\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3d70d49",
   "metadata": {},
   "source": [
    "## precompiple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b3283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-20 12:50:18.000261: INFO ||PARALLEL_COMPILE||: Running trial run (add option to terminate trial run early; also ignore trial run's generated outputs, i.e. loss, checkpoints)\n",
      "is precompilation: 1\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running training *****\n",
      "  Num examples = 20\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 20\n",
      "  Number of trainable parameters = 109541453\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]2023-03-20 12:50:30.000934: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.206_16122647675228413938.hlo.pb \n",
      "2023-03-20 12:50:30.000936: INFO ||NCC_WRAPPER||: No candidate found under /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16122647675228413938.\n",
      "2023-03-20 12:50:30.000936: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16122647675228413938/MODULE_SyncTensorsGraph.206_16122647675228413938/c5708278-e89c-426a-915f-bb0b02530ae3\n",
      "2023-03-20 12:50:30.000987: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      "  5%|▌         | 1/20 [00:00<00:06,  2.94it/s]2023-03-20 12:50:32.000136: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.21235_10629745062415984739.hlo.pb \n",
      "2023-03-20 12:50:32.000136: INFO ||NCC_WRAPPER||: No candidate found under /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_10629745062415984739.\n",
      "2023-03-20 12:50:32.000137: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_10629745062415984739/MODULE_SyncTensorsGraph.21235_10629745062415984739/dda69618-1b13-405e-98f4-b2bb0eed26d8\n",
      "2023-03-20 12:50:32.000142: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 10%|█         | 2/20 [00:02<00:22,  1.28s/it]2023-03-20 12:50:34.000199: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.21235_13287049978593524563.hlo.pb \n",
      "2023-03-20 12:50:34.000199: INFO ||NCC_WRAPPER||: No candidate found under /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13287049978593524563.\n",
      "2023-03-20 12:50:34.000201: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13287049978593524563/MODULE_SyncTensorsGraph.21235_13287049978593524563/2c94a05b-7a7c-460c-83d2-3b64b1361479\n",
      "2023-03-20 12:50:34.000205: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      " 55%|█████▌    | 11/20 [00:05<00:02,  4.06it/s]2023-03-20 12:50:37.000085: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.21235_12744209621922340756.hlo.pb \n",
      "2023-03-20 12:50:37.000086: INFO ||NCC_WRAPPER||: No candidate found under /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12744209621922340756.\n",
      "2023-03-20 12:50:37.000087: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12744209621922340756/MODULE_SyncTensorsGraph.21235_12744209621922340756/cbcdbd32-9bab-4172-b83d-cca5adbf19ac\n",
      "2023-03-20 12:50:37.000091: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      "100%|██████████| 20/20 [00:07<00:00,  5.81it/s]Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n",
      "2023-03-20 12:50:38.000941: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4547_7217610760572606364.hlo.pb \n",
      "2023-03-20 12:50:38.000941: INFO ||NCC_WRAPPER||: No candidate found under /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_7217610760572606364.\n",
      "2023-03-20 12:50:38.000941: INFO ||NCC_WRAPPER||: Cache dir for the neff: /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_7217610760572606364/MODULE_SyncTensorsGraph.4547_7217610760572606364/a8e2e45d-2af7-46bb-8b4f-73c8edb7963b\n",
      "2023-03-20 12:50:38.000945: INFO ||NCC_WRAPPER||: Extracting graphs for ahead-of-time parallel compilation. Nocompilation was done.\n",
      "2023-03-20 12:50:39.000069: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_1002868706066901398.hlo.pb \n",
      "2023-03-20 12:50:39.000073: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_SyncTensorsGraph.4_1002868706066901398/8121fb1e-f175-4f7a-baaa-14a326a19083/MODULE_SyncTensorsGraph.4_1002868706066901398.neff. Exiting with a successfully compiled graph\n",
      "2023-03-20 12:50:39.000138: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.4_14019065114978382472.hlo.pb \n",
      "2023-03-20 12:50:39.000142: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_SyncTensorsGraph.4_14019065114978382472/5d49a674-a046-424b-9e79-b5d4db41e0d1/MODULE_SyncTensorsGraph.4_14019065114978382472.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-03-20 12:50:39.000277: DEBUG ||NCC_WRAPPER||: Compiling HLO: /tmp/MODULE_SyncTensorsGraph.21_4080407439719223453.hlo.pb \n",
      "2023-03-20 12:50:39.000281: INFO ||NCC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_4080407439719223453/MODULE_SyncTensorsGraph.21_4080407439719223453/6d5db888-0e91-4f3b-b394-f3e429abe279/MODULE_SyncTensorsGraph.21_4080407439719223453.neff. Exiting with a successfully compiled graph\n",
      "\n",
      " 50%|█████     | 5/10 [00:00<00:00, 36.74it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "\u001b[A{'eval_loss': 7.651089615213501e-43, 'eval_f1': 0.0, 'eval_runtime': 0.7057, 'eval_samples_per_second': 14.169, 'eval_steps_per_second': 2.834, 'epoch': 1.0}\n",
      "100%|██████████| 20/20 [00:08<00:00,  5.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.04it/s]\u001b[A\n",
      "                                               \u001b[ASaving model checkpoint to run1/checkpoint-20\n",
      "Configuration saved in run1/checkpoint-20/config.json\n",
      "Model weights saved in run1/checkpoint-20/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from run1/checkpoint-20 (score: 0.0).\n",
      "{'train_runtime': 20.1149, 'train_samples_per_second': 0.994, 'train_steps_per_second': 0.994, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "100%|██████████| 20/20 [00:20<00:00,  1.01s/it]\n",
      "tokenizer config file saved in run1/tokenizer_config.json\n",
      "Special tokens file saved in run1/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'dataset': {'name': 'banking77', 'type': 'banking77', 'config': 'default', 'split': 'test', 'args': 'default'}}\n",
      "2023-03-20 12:50:52.000744: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs\n",
      "2023-03-20 12:50:52.000745: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.4547_7217610760572606364.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.4547_7217610760572606364.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.4547_7217610760572606364.neff\n",
      "2023-03-20 12:50:52.000746: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_12744209621922340756.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_12744209621922340756.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_12744209621922340756.neff\n",
      "........\n",
      "Compiler status PASS\n",
      "2023-03-20 12:51:59.000098: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.206_16122647675228413938.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.206_16122647675228413938.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.206_16122647675228413938.neff\n",
      ".\n",
      "Compiler status PASS\n",
      "2023-03-20 12:52:02.000388: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_10629745062415984739.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_10629745062415984739.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_10629745062415984739.neff\n",
      "............................\n",
      "Compiler status PASS\n",
      "2023-03-20 12:56:36.000039: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_13287049978593524563.hlo.pb using following command: neuronx-cc compile --target=trn1 --framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_13287049978593524563.hlo.pb --model-type=transformer --verbose=35 --output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_13287049978593524563.neff\n",
      "...................................\n",
      "Compiler status PASS\n",
      "..............\n",
      "Compiler status PASS\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation summary:\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.4547_7217610760572606364.hlo.pb was successful. Plugged neff in the cache dir: /var/tmp\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.206_16122647675228413938.hlo.pb was successful. Plugged neff in the cache dir: /var/tmp\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_12744209621922340756.hlo.pb was successful. Plugged neff in the cache dir: /var/tmp\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_10629745062415984739.hlo.pb was successful. Plugged neff in the cache dir: /var/tmp\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Compilation of /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21235_13287049978593524563.hlo.pb was successful. Plugged neff in the cache dir: /var/tmp\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Total graphs: 5\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Total successful compilations: 5\n",
      "2023-03-20 13:07:15.000337: INFO ||PARALLEL_COMPILE||: Total failed compilations: 0\n"
     ]
    }
   ],
   "source": [
    "!neuron_parallel_compile python3 scripts/train.py --model_id bert-base-uncased --per_device_train_batch_size 8 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01bff4e",
   "metadata": {},
   "source": [
    "`2023-03-13 08:24:52.000851: ERROR ||PARALLEL_COMPILE||: parallel compilation with neuronx-cc exited with error.Received error code: 137`\n",
    "\n",
    "=> OOM? but training with BS 8 works. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "280aa609",
   "metadata": {},
   "source": [
    "```\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total graphs: 2\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total successful compilations: 0\n",
    "2023-03-13 08:26:28.000757: INFO ||PARALLEL_COMPILE||: Total failed compilations: 2\n",
    "```\n",
    "\n",
    "monitoring `htop` has shown that we ran out of CPU Memory -> (30.8GB)\n",
    "\n",
    "`free -h`\n",
    "\n",
    "shows no swap \n",
    "\n",
    "\n",
    "```bash\n",
    "# add swap 10GB of swap\n",
    "sudo fallocate -l 20G /swapfile\n",
    "# change permissions\n",
    "sudo chmod 600 /swapfile\n",
    "# mark the file as swap space\n",
    "sudo mkswap /swapfile\n",
    "# enable swap \n",
    "sudo swapon /swapfile\n",
    "# make swap file permanent\n",
    "# echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab\n",
    "```\n",
    "\n",
    "20 GB was not enough! 🤯\n",
    "\n",
    "\n",
    "![img](./im.png)\n",
    "\n",
    "switch swap: https://askubuntu.com/questions/1264568/increase-swap-in-20-04"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8dc0746",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c439f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /var/tmp/neuron-compile-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d771d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 39.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface_hub) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface_hub) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2.8)\n",
      "Installing collected packages: huggingface-hub\n",
      "Successfully installed huggingface-hub-0.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92badd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "huggingface_hub.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46728a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "is precompilation: None\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running training *****\n",
      "  Num examples = 10,003\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,753\n",
      "  Number of trainable parameters = 108,369,485\n",
      "  0%|                                                  | 0/3753 [00:00<?, ?it/s]2023-04-19 16:16:26.000379: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_11106224588283224741/MODULE_0_SyncTensorsGraph.206_11106224588283224741_ip-172-31-79-164-ce19e43-171934-5f9b12b2323e8/16554e11-1e84-4c76-857f-7253db730136/MODULE_0_SyncTensorsGraph.206_11106224588283224741_ip-172-31-79-164-ce19e43-171934-5f9b12b2323e8.neff. Exiting with a successfully compiled graph\n",
      "  0%|                                        | 1/3753 [00:02<2:48:02,  2.69s/it]2023-04-19 16:16:29.000910: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13414546418265479071.\n",
      "2023-04-19 16:16:29.000911: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13414546418265479071/MODULE_1_SyncTensorsGraph.21235_13414546418265479071_ip-172-31-79-164-8126df14-805258-5f9b2bf243a22/88a37610-e70b-4fda-9d4b-3172ed0223d6\n",
      "...............................\n",
      "Compiler status PASS\n",
      "2023-04-19 16:26:37.000504: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "  0%|                                     | 2/3753 [10:12<374:46:08, 359.68s/it]2023-04-19 16:26:56.000686: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14842232154424896350.\n",
      "2023-04-19 16:26:56.000687: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14842232154424896350/MODULE_2_SyncTensorsGraph.21235_14842232154424896350_ip-172-31-79-164-26f20404-805258-5f9b2e4801086/32360ccc-6e3b-4e00-b3d2-ef7ffe40039d\n",
      "................................\n",
      "Compiler status PASS\n",
      "2023-04-19 16:37:21.000332: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      " 13%|█████▎                                  | 500/3753 [22:59<11:06,  4.88it/s]2023-04-19 16:39:26.000192: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13378262660058097712/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-1dd8a08f-171934-5f9b1578cb97e/9b80c97f-b056-431c-a061-fcced341f115/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-1dd8a08f-171934-5f9b1578cb97e.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 3.9196, 'learning_rate': 4.333866240341061e-05, 'epoch': 0.4}          \n",
      " 13%|█████▎                                  | 500/3753 [22:59<11:06,  4.88it/s]2023-04-19 16:39:26.000262: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_3455400400948827543/MODULE_4_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-914aefe-171934-5f9b158e313f8/41513a5d-c3b2-43a3-bb2b-ef9f23757b62/MODULE_4_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-914aefe-171934-5f9b158e313f8.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 2.6744, 'learning_rate': 3.667732480682121e-05, 'epoch': 0.8}          \n",
      " 33%|█████████████                          | 1251/3753 [25:37<39:07,  1.07it/s]2023-04-19 16:42:04.000791: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_3761737345989402480.\n",
      "2023-04-19 16:42:04.000792: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_3761737345989402480/MODULE_5_SyncTensorsGraph.21235_3761737345989402480_ip-172-31-79-164-5673e3e8-805258-5f9b31aa0a582/6bc41d8a-471a-46fa-a56f-c1e68c58da2f\n",
      "................\n",
      "Compiler status PASS\n",
      "2023-04-19 16:47:26.000682: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "Saving model checkpoint to run1/checkpoint-1251\n",
      "Deleting older checkpoint [run1/checkpoint-626] due to args.save_total_limit\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_1_SyncTensorsGraph.21235_13414546418265479071_8126df14-805258-5f9b2bf243a\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.91it/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_1_SyncTensorsGraph.21235_13414546418265479071_8126df14-805258-5f9b2bf243a\u001b[A\u001b[A\n",
      "\n",
      "MODULE_1_SyncTensorsGraph.21235_13414546418265479071_8126df14-805258-5f9b2bf243a\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.58it/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_2_SyncTensorsGraph.21235_14842232154424896350_26f20404-805258-5f9b2e48010\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  5.55it/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_2_SyncTensorsGraph.21235_14842232154424896350_26f20404-805258-5f9b2e48010\u001b[A\u001b[A\n",
      "\n",
      "MODULE_2_SyncTensorsGraph.21235_14842232154424896350_26f20404-805258-5f9b2e48010\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\u001b[A\n",
      "{'loss': 1.9356, 'learning_rate': 3.0015987210231815e-05, 'epoch': 1.2}         \n",
      "{'loss': 1.4792, 'learning_rate': 2.335464961364242e-05, 'epoch': 1.6}          \n",
      "{'loss': 1.2959, 'learning_rate': 1.6693312017053024e-05, 'epoch': 2.0}         \n",
      " 67%|█████████████████████████▉             | 2501/3753 [35:40<05:39,  3.69it/s]Saving model checkpoint to run1/checkpoint-2502\n",
      "Deleting older checkpoint [run1/checkpoint-1878] due to args.save_total_limit\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_5_SyncTensorsGraph.21235_3761737345989402480_5673e3e8-805258-5f9b31aa0a58\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.81it/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_5_SyncTensorsGraph.21235_3761737345989402480_5673e3e8-805258-5f9b31aa0a58\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  5.55it/s]\u001b[A\n",
      "{'loss': 1.0193, 'learning_rate': 1.003197442046363e-05, 'epoch': 2.4}          \n",
      "{'loss': 0.9497, 'learning_rate': 3.370636823874234e-06, 'epoch': 2.8}          \n",
      "100%|███████████████████████████████████████| 3753/3753 [40:07<00:00,  4.80it/s]Saving model checkpoint to run1/checkpoint-3753\n",
      "2023-04-19 16:56:35.000004: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8857771530603576139.\n",
      "2023-04-19 16:56:35.000005: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8857771530603576139/MODULE_6_SyncTensorsGraph.20226_8857771530603576139_ip-172-31-79-164-cdf59bb5-805258-5f9b34e7f0d32/29a9523f-f9f6-498e-8804-d0161fbe8f87\n",
      "...............\n",
      "Compiler status PASS\n",
      "2023-04-19 17:01:31.000405: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "2023-04-19 17:01:40.000198: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_2454971917652588918.\n",
      "2023-04-19 17:01:40.000199: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_2454971917652588918/MODULE_7_SyncTensorsGraph.18415_2454971917652588918_ip-172-31-79-164-beae158d-805258-5f9b360afc36b/7b80c7b7-fa55-4e8b-9023-5c7948bfa2ba\n",
      "...............\n",
      "Compiler status PASS\n",
      "2023-04-19 17:06:36.000859: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "Deleting older checkpoint [run1/checkpoint-1251] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "2023-04-19 17:06:45.000952: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16408249091491318990.\n",
      "2023-04-19 17:06:45.000953: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16408249091491318990/MODULE_8_SyncTensorsGraph.5868_16408249091491318990_ip-172-31-79-164-97a49e06-805258-5f9b372e9226f/d7e85178-aabb-4356-9b87-e02906690a12\n",
      "...\n",
      "Compiler status PASS\n",
      "2023-04-19 17:07:40.000975: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "{'train_runtime': 3075.2905, 'train_samples_per_second': 9.758, 'train_steps_per_second': 1.22, 'train_loss': 1.8313741015651022, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 3753/3753 [51:15<00:00,  1.22it/s]\n",
      "Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 8\n",
      "2023-04-19 17:07:41.000681: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16012244068486249943.\n",
      "2023-04-19 17:07:41.000682: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16012244068486249943/MODULE_9_SyncTensorsGraph.1007_16012244068486249943_ip-172-31-79-164-aa19778a-805258-5f9b3763bbdc0/b80d17a8-5634-4fa1-add8-f55ebe15f9ce\n",
      ".\n",
      "Compiler status PASS\n",
      "2023-04-19 17:07:50.000624: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "2023-04-19 17:07:50.000863: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6506440068181678665.\n",
      "2023-04-19 17:07:50.000863: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6506440068181678665/MODULE_10_SyncTensorsGraph.4547_6506440068181678665_ip-172-31-79-164-bb9e3054-805258-5f9b376c7d484/9c977ff2-8869-4bfd-bacb-7e34d6c9164c\n",
      "....\n",
      "Compiler status PASS\n",
      "2023-04-19 17:09:05.000040: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "2023-04-19 17:09:06.000419: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_10_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-6a44992f-330621-5f9b1cdbad631/ac579c27-e071-4478-b02e-ab8610678a59/MODULE_10_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-6a44992f-330621-5f9b1cdbad631.neff. Exiting with a successfully compiled graph\n",
      "2023-04-19 17:09:06.000574: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-04-19 17:09:06.000579: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpnh36a7iv/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_11_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-46b702ff-330621-5f9b1cde1f831/18366b6e-7265-41a0-9f9b-2eb5c74cd49f/MODULE_11_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-46b702ff-330621-5f9b1cde1f831.neff. Exiting with a successfully compiled graph\n",
      "100%|█████████████████████████████████████████| 385/385 [00:26<00:00, 14.69it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_10_SyncTensorsGraph.4547_6506440068181678665_bb9e3054-805258-5f9b376c7d48\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  5.10it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_10_SyncTensorsGraph.4547_6506440068181678665_bb9e3054-805258-5f9b376c7d48\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_7_SyncTensorsGraph.18415_2454971917652588918_beae158d-805258-5f9b360afc36\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_7_SyncTensorsGraph.18415_2454971917652588918_beae158d-805258-5f9b360afc36\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.75it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_6_SyncTensorsGraph.20226_8857771530603576139_cdf59bb5-805258-5f9b34e7f0d3\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.52it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_6_SyncTensorsGraph.20226_8857771530603576139_cdf59bb5-805258-5f9b34e7f0d3\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_9_SyncTensorsGraph.1007_16012244068486249943_aa19778a-805258-5f9b3763bbdc\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  6.06it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_8_SyncTensorsGraph.5868_16408249091491318990_97a49e06-805258-5f9b372e9226\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_8_SyncTensorsGraph.5868_16408249091491318990_97a49e06-805258-5f9b372e9226\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  5.66it/s]\n"
     ]
    }
   ],
   "source": [
    "!CUSTOM_CACHE_REPO=philschmid/neuron-cache python3 scripts/train.py  --model_id bert-base-cased --per_device_train_batch_size 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ae31815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:__main__:Process rank: -1, device: xla:1, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "/home/ubuntu/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n",
      "WARNING:datasets.builder:Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 697.13it/s]\n",
      "[WARNING|modeling_utils.py:3180] 2023-04-19 18:38:49,220 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3192] 2023-04-19 18:38:49,220 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-8a4bef8cbb7d2d6c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-a6ccd2cfc828d15a.arrow\n",
      "[INFO|trainer.py:762] 2023-04-19 18:38:53,360 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainers.py:119] 2023-04-19 18:38:53,365 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:1769] 2023-04-19 18:38:53,365 >> ***** Running training *****\n",
      "[INFO|trainer.py:1770] 2023-04-19 18:38:53,365 >>   Num examples = 10,003\n",
      "[INFO|trainer.py:1771] 2023-04-19 18:38:53,365 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1772] 2023-04-19 18:38:53,365 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1773] 2023-04-19 18:38:53,365 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1774] 2023-04-19 18:38:53,365 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1775] 2023-04-19 18:38:53,365 >>   Total optimization steps = 3,753\n",
      "[INFO|trainer.py:1776] 2023-04-19 18:38:53,366 >>   Number of trainable parameters = 108,369,485\n",
      "  0%|                                                  | 0/3753 [00:00<?, ?it/s]2023-04-19 18:38:53.000452: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_11106224588283224741/MODULE_0_SyncTensorsGraph.206_11106224588283224741_ip-172-31-79-164-ce19e43-171934-5f9b12b2323e8/16554e11-1e84-4c76-857f-7253db730136/MODULE_0_SyncTensorsGraph.206_11106224588283224741_ip-172-31-79-164-ce19e43-171934-5f9b12b2323e8.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "Fetching 36 files:   0%|                                 | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Downloading (…)4-5f9b12b2323e8.neff: 100%|███| 169k/169k [00:00<00:00, 54.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)59/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 3.99kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1cdbad631.hlo.pb:   0%|            | 0.00/330 [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1cdbad631.hlo.pb: 100%|█████| 330/330 [00:00<00:00, 38.9kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)1-5f9b1cdbad631.neff: 100%|█| 8.19k/8.19k [00:00<00:00, 1.87MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)1-5f9b1a95141f5.neff: 100%|███| 916k/916k [00:00<00:00, 34.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b1578cb97e.neff:   0%|          | 0.00/7.80k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b1578cb97e.neff: 100%|██| 7.80k/7.80k [00:00<00:00, 908kB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)36/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 4.97kB/s]\n",
      "\n",
      "\n",
      "Downloading (…)a4/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 5.31kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)1-5f9b1cde1f831.neff: 100%|█| 7.89k/7.89k [00:00<00:00, 4.96MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1a95141f5.hlo.pb:   0%|           | 0.00/291k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b12b2323e8.hlo.pb: 100%|█| 40.6k/40.6k [00:00<00:00, 30.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)5f9b1a95141f5.hlo.pb: 100%|███| 291k/291k [00:00<00:00, 24.0MB/s]\n",
      "\n",
      "Fetching 36 files:  17%|████▏                    | 6/36 [00:00<00:01, 26.58it/s]\u001b[A\n",
      "\n",
      "Downloading (…)5f9b1578cb97e.hlo.pb: 100%|██████| 326/326 [00:00<00:00, 252kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)9f/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 19.7kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1cde1f831.hlo.pb: 100%|██████| 365/365 [00:00<00:00, 307kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)15/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 19.7kB/s]\u001b[A\u001b[A\n",
      "\n",
      "Fetching 36 files:  31%|███████▎                | 11/36 [00:00<00:00, 35.17it/s]\u001b[A\n",
      "\n",
      "Downloading (…)1-5f9b1cb72a036.neff:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1abcee516.hlo.pb:   0%|          | 0.00/1.13M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1cb72a036.hlo.pb:   0%|           | 0.00/207k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)1-5f9b1cb72a036.neff: 100%|█| 1.39M/1.39M [00:00<00:00, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)6a/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 14.6kB/s]\n",
      "Downloading (…)5f9b1cb72a036.hlo.pb: 100%|███| 207k/207k [00:00<00:00, 31.9MB/s]\n",
      "Downloading (…)5f9b1abcee516.hlo.pb: 100%|█| 1.13M/1.13M [00:00<00:00, 49.7MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)f2/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 19.6kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)1-5f9b1abcee516.neff:   0%|          | 0.00/6.29M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b158e313f8.neff: 100%|█| 8.22k/8.22k [00:00<00:00, 6.61MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)1-5f9b1be1b0638.neff: 100%|██| 6.26M/6.26M [00:00<00:00, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9b158e313f8.hlo.pb: 100%|██████| 401/401 [00:00<00:00, 294kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)9a/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 16.6kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9b1be1b0638.hlo.pb:   0%|          | 0.00/1.14M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)1-5f9b1abcee516.neff: 100%|█| 6.29M/6.29M [00:00<00:00, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)5f9b1be1b0638.hlo.pb: 100%|█| 1.14M/1.14M [00:00<00:00, 24.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)91/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 14.5kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b12b98d874.neff:   0%|          | 0.00/8.41M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b13ec68262.hlo.pb:   0%|          | 0.00/1.27M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)62/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 16.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)5f9b13ec68262.hlo.pb: 100%|█| 1.27M/1.27M [00:00<00:00, 63.0MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9b12b98d874.hlo.pb: 100%|█| 1.20M/1.20M [00:00<00:00, 73.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)7b/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 18.4kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b15dbcd855.neff: 100%|██| 7.09M/7.09M [00:00<00:00, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b12b98d874.neff: 100%|█| 8.41M/8.41M [00:00<00:00, 44.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Fetching 36 files:  86%|████████████████████▋   | 31/36 [00:00<00:00, 36.19it/s]\u001b[A\n",
      "\n",
      "Downloading (…)93/compile_flags.txt: 100%|███| 24.0/24.0 [00:00<00:00, 18.9kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9b15dbcd855.hlo.pb: 100%|█| 1.27M/1.27M [00:00<00:00, 85.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)4-5f9b13ec68262.neff: 100%|██| 9.35M/9.35M [00:00<00:00, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Fetching 36 files: 100%|████████████████████████| 36/36 [00:01<00:00, 34.90it/s]\u001b[A\n",
      "  0%|                                        | 1/3753 [00:03<3:45:00,  3.60s/it]2023-04-19 18:38:57.000921: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_4626190721083803594/MODULE_1_SyncTensorsGraph.21237_4626190721083803594_ip-172-31-79-164-ee105f1f-171934-5f9b12b98d874/bd340c85-3804-464d-879a-ab837cde5791/MODULE_1_SyncTensorsGraph.21237_4626190721083803594_ip-172-31-79-164-ee105f1f-171934-5f9b12b98d874.neff. Exiting with a successfully compiled graph\n",
      "  0%|                                        | 2/3753 [00:05<2:40:30,  2.57s/it]2023-04-19 18:39:01.000880: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6454899324413167499/MODULE_2_SyncTensorsGraph.21237_6454899324413167499_ip-172-31-79-164-d3323312-171934-5f9b13ec68262/c70a6095-8f10-49c4-9582-4607d960117b/MODULE_2_SyncTensorsGraph.21237_6454899324413167499_ip-172-31-79-164-d3323312-171934-5f9b13ec68262.neff. Exiting with a successfully compiled graph\n",
      " 13%|█████▎                                  | 500/3753 [00:47<03:58, 13.65it/s]2023-04-19 18:39:40.000530: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13378262660058097712/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-1dd8a08f-171934-5f9b1578cb97e/9b80c97f-b056-431c-a061-fcced341f115/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-1dd8a08f-171934-5f9b1578cb97e.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 3.5349, 'learning_rate': 4.333866240341061e-05, 'epoch': 0.4}          \n",
      " 13%|█████▎                                  | 500/3753 [00:47<03:58, 13.65it/s][INFO|trainer.py:2838] 2023-04-19 18:39:40,549 >> Saving model checkpoint to ./run23434/checkpoint-500\n",
      "2023-04-19 18:39:43.000941: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_3455400400948827543/MODULE_4_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-914aefe-171934-5f9b158e313f8/41513a5d-c3b2-43a3-bb2b-ef9f23757b62/MODULE_4_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-914aefe-171934-5f9b158e313f8.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 1.8796, 'learning_rate': 3.667732480682121e-05, 'epoch': 0.8}          \n",
      " 27%|██████████▍                            | 1000/3753 [01:26<03:18, 13.85it/s][INFO|trainer.py:2838] 2023-04-19 18:40:19,924 >> Saving model checkpoint to ./run23434/checkpoint-1000\n",
      " 33%|████████████▉                          | 1250/3753 [01:47<02:59, 13.96it/s]2023-04-19 18:40:44.000416: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_9847303456036543666/MODULE_5_SyncTensorsGraph.21237_9847303456036543666_ip-172-31-79-164-acb290d2-171934-5f9b15dbcd855/012cae56-e12c-4559-99ae-f369e1667693/MODULE_5_SyncTensorsGraph.21237_9847303456036543666_ip-172-31-79-164-acb290d2-171934-5f9b15dbcd855.neff. Exiting with a successfully compiled graph\n",
      "[INFO|trainer.py:762] 2023-04-19 18:40:47,058 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 18:40:47,060 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 18:40:47,060 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 18:40:47,060 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 18:40:47,060 >>   Batch size = 8\n",
      "2023-04-19 18:40:47.000297: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14480935013817541190/MODULE_9_SyncTensorsGraph.4548_14480935013817541190_ip-172-31-79-164-875ff48a-330621-5f9b1cb72a036/e94814cf-f7da-453d-80c2-d3bdd64c8b6a/MODULE_9_SyncTensorsGraph.4548_14480935013817541190_ip-172-31-79-164-875ff48a-330621-5f9b1cb72a036.neff. Exiting with a successfully compiled graph\n",
      "2023-04-19 18:40:47.000628: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_10_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-6a44992f-330621-5f9b1cdbad631/ac579c27-e071-4478-b02e-ab8610678a59/MODULE_10_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-6a44992f-330621-5f9b1cdbad631.neff. Exiting with a successfully compiled graph\n",
      "2023-04-19 18:40:47.000702: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags '--model-type=transformer'\n",
      "2023-04-19 18:40:47.000704: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmp2vl2rqqh/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_11_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-46b702ff-330621-5f9b1cde1f831/18366b6e-7265-41a0-9f9b-2eb5c74cd49f/MODULE_11_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-46b702ff-330621-5f9b1cde1f831.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|                                                   | 0/385 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                          | 4/385 [00:00<00:11, 32.93it/s]\u001b[A\n",
      "  2%|▉                                          | 8/385 [00:00<00:12, 30.16it/s]\u001b[A\n",
      "  3%|█▎                                        | 12/385 [00:00<00:12, 29.46it/s]\u001b[A\n",
      "  4%|█▋                                        | 15/385 [00:00<00:12, 29.58it/s]\u001b[A\n",
      "  5%|█▉                                        | 18/385 [00:00<00:12, 29.17it/s]\u001b[A\n",
      "  5%|██▎                                       | 21/385 [00:00<00:12, 28.84it/s]\u001b[A\n",
      "  6%|██▌                                       | 24/385 [00:00<00:12, 28.73it/s]\u001b[A\n",
      "  7%|███                                       | 28/385 [00:00<00:12, 28.79it/s]\u001b[A\n",
      "  8%|███▍                                      | 32/385 [00:01<00:12, 28.81it/s]\u001b[A\n",
      "  9%|███▊                                      | 35/385 [00:01<00:12, 29.11it/s]\u001b[A\n",
      " 10%|████▏                                     | 38/385 [00:01<00:12, 28.91it/s]\u001b[A\n",
      " 11%|████▍                                     | 41/385 [00:01<00:12, 28.66it/s]\u001b[A\n",
      " 11%|████▊                                     | 44/385 [00:01<00:11, 28.58it/s]\u001b[A\n",
      " 12%|█████▏                                    | 48/385 [00:01<00:11, 28.72it/s]\u001b[A\n",
      " 13%|█████▌                                    | 51/385 [00:01<00:11, 29.03it/s]\u001b[A\n",
      " 14%|█████▉                                    | 54/385 [00:01<00:11, 28.86it/s]\u001b[A\n",
      " 15%|██████▏                                   | 57/385 [00:01<00:11, 28.67it/s]\u001b[A\n",
      " 16%|██████▌                                   | 60/385 [00:02<00:11, 28.37it/s]\u001b[A\n",
      " 16%|██████▊                                   | 63/385 [00:02<00:11, 28.56it/s]\u001b[A\n",
      " 17%|███████▏                                  | 66/385 [00:02<00:11, 28.37it/s]\u001b[A\n",
      " 18%|███████▌                                  | 69/385 [00:02<00:11, 28.10it/s]\u001b[A\n",
      " 19%|███████▊                                  | 72/385 [00:02<00:11, 27.95it/s]\u001b[A\n",
      " 19%|████████▏                                 | 75/385 [00:02<00:10, 28.34it/s]\u001b[A\n",
      " 20%|████████▌                                 | 78/385 [00:02<00:10, 28.12it/s]\u001b[A\n",
      " 21%|████████▊                                 | 81/385 [00:02<00:10, 28.10it/s]\u001b[A\n",
      " 22%|█████████▏                                | 84/385 [00:02<00:10, 28.07it/s]\u001b[A\n",
      " 23%|█████████▍                                | 87/385 [00:03<00:10, 28.58it/s]\u001b[A\n",
      " 23%|█████████▊                                | 90/385 [00:03<00:10, 28.34it/s]\u001b[A\n",
      " 24%|██████████▏                               | 93/385 [00:03<00:10, 28.07it/s]\u001b[A\n",
      " 25%|██████████▍                               | 96/385 [00:03<00:10, 27.95it/s]\u001b[A\n",
      " 26%|██████████▊                               | 99/385 [00:03<00:10, 28.46it/s]\u001b[A\n",
      " 26%|██████████▊                              | 102/385 [00:03<00:10, 28.27it/s]\u001b[A\n",
      " 27%|███████████▏                             | 105/385 [00:03<00:09, 28.19it/s]\u001b[A\n",
      " 28%|███████████▌                             | 108/385 [00:03<00:09, 27.95it/s]\u001b[A\n",
      " 29%|███████████▊                             | 111/385 [00:03<00:09, 28.42it/s]\u001b[A\n",
      " 30%|████████████▏                            | 114/385 [00:03<00:09, 28.23it/s]\u001b[A\n",
      " 30%|████████████▍                            | 117/385 [00:04<00:09, 27.95it/s]\u001b[A\n",
      " 31%|████████████▊                            | 120/385 [00:04<00:09, 27.79it/s]\u001b[A\n",
      " 32%|█████████████▏                           | 124/385 [00:04<00:09, 28.14it/s]\u001b[A\n",
      " 33%|█████████████▌                           | 127/385 [00:04<00:09, 28.43it/s]\u001b[A\n",
      " 34%|█████████████▊                           | 130/385 [00:04<00:09, 28.17it/s]\u001b[A\n",
      " 35%|██████████████▏                          | 133/385 [00:04<00:08, 28.13it/s]\u001b[A\n",
      " 35%|██████████████▍                          | 136/385 [00:04<00:08, 27.90it/s]\u001b[A\n",
      " 36%|██████████████▊                          | 139/385 [00:04<00:08, 27.45it/s]\u001b[A\n",
      " 37%|███████████████                          | 142/385 [00:04<00:08, 27.61it/s]\u001b[A\n",
      " 38%|███████████████▍                         | 145/385 [00:05<00:08, 27.71it/s]\u001b[A\n",
      " 38%|███████████████▊                         | 148/385 [00:05<00:08, 27.81it/s]\u001b[A\n",
      " 39%|████████████████                         | 151/385 [00:05<00:08, 28.26it/s]\u001b[A\n",
      " 40%|████████████████▍                        | 154/385 [00:05<00:08, 28.09it/s]\u001b[A\n",
      " 41%|████████████████▋                        | 157/385 [00:05<00:08, 28.07it/s]\u001b[A\n",
      " 42%|█████████████████                        | 160/385 [00:05<00:07, 28.16it/s]\u001b[A\n",
      " 42%|█████████████████▎                       | 163/385 [00:05<00:07, 28.33it/s]\u001b[A\n",
      " 43%|█████████████████▋                       | 166/385 [00:05<00:07, 28.08it/s]\u001b[A\n",
      " 44%|█████████████████▉                       | 169/385 [00:05<00:07, 28.01it/s]\u001b[A\n",
      " 45%|██████████████████▎                      | 172/385 [00:06<00:07, 28.00it/s]\u001b[A\n",
      " 45%|██████████████████▋                      | 175/385 [00:06<00:07, 28.23it/s]\u001b[A\n",
      " 46%|██████████████████▉                      | 178/385 [00:06<00:07, 27.99it/s]\u001b[A\n",
      " 47%|███████████████████▎                     | 181/385 [00:06<00:07, 27.95it/s]\u001b[A\n",
      " 48%|███████████████████▌                     | 184/385 [00:06<00:07, 27.74it/s]\u001b[A\n",
      " 49%|███████████████████▉                     | 187/385 [00:06<00:07, 28.00it/s]\u001b[A\n",
      " 49%|████████████████████▏                    | 190/385 [00:06<00:06, 27.90it/s]\u001b[A\n",
      " 50%|████████████████████▌                    | 193/385 [00:06<00:06, 27.84it/s]\u001b[A\n",
      " 51%|████████████████████▊                    | 196/385 [00:06<00:06, 27.80it/s]\u001b[A\n",
      " 52%|█████████████████████▏                   | 199/385 [00:07<00:06, 28.35it/s]\u001b[A\n",
      " 52%|█████████████████████▌                   | 202/385 [00:07<00:06, 28.33it/s]\u001b[A\n",
      " 53%|█████████████████████▊                   | 205/385 [00:07<00:06, 28.13it/s]\u001b[A\n",
      " 54%|██████████████████████▏                  | 208/385 [00:07<00:06, 27.97it/s]\u001b[A\n",
      " 55%|██████████████████████▌                  | 212/385 [00:07<00:06, 28.21it/s]\u001b[A\n",
      " 56%|██████████████████████▉                  | 215/385 [00:07<00:05, 28.56it/s]\u001b[A\n",
      " 57%|███████████████████████▏                 | 218/385 [00:07<00:05, 28.40it/s]\u001b[A\n",
      " 57%|███████████████████████▌                 | 221/385 [00:07<00:05, 28.35it/s]\u001b[A\n",
      " 58%|███████████████████████▊                 | 224/385 [00:07<00:05, 28.14it/s]\u001b[A\n",
      " 59%|████████████████████████▏                | 227/385 [00:08<00:05, 28.39it/s]\u001b[A\n",
      " 60%|████████████████████████▍                | 230/385 [00:08<00:05, 28.14it/s]\u001b[A\n",
      " 61%|████████████████████████▊                | 233/385 [00:08<00:05, 27.98it/s]\u001b[A\n",
      " 61%|█████████████████████████▏               | 236/385 [00:08<00:05, 27.95it/s]\u001b[A\n",
      " 62%|█████████████████████████▍               | 239/385 [00:08<00:05, 28.30it/s]\u001b[A\n",
      " 63%|█████████████████████████▊               | 242/385 [00:08<00:05, 28.04it/s]\u001b[A\n",
      " 64%|██████████████████████████               | 245/385 [00:08<00:04, 28.10it/s]\u001b[A\n",
      " 64%|██████████████████████████▍              | 248/385 [00:08<00:04, 28.01it/s]\u001b[A\n",
      " 65%|██████████████████████████▋              | 251/385 [00:08<00:04, 28.19it/s]\u001b[A\n",
      " 66%|███████████████████████████              | 254/385 [00:08<00:04, 27.49it/s]\u001b[A\n",
      " 67%|███████████████████████████▎             | 257/385 [00:09<00:04, 27.27it/s]\u001b[A\n",
      " 68%|███████████████████████████▋             | 260/385 [00:09<00:04, 27.35it/s]\u001b[A\n",
      " 68%|████████████████████████████             | 263/385 [00:09<00:04, 27.84it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 266/385 [00:09<00:04, 27.68it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 269/385 [00:09<00:04, 27.71it/s]\u001b[A\n",
      " 71%|████████████████████████████▉            | 272/385 [00:09<00:04, 27.82it/s]\u001b[A\n",
      " 71%|█████████████████████████████▎           | 275/385 [00:09<00:03, 27.96it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 278/385 [00:09<00:03, 28.01it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 281/385 [00:09<00:03, 28.00it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 284/385 [00:10<00:03, 27.96it/s]\u001b[A\n",
      " 75%|██████████████████████████████▋          | 288/385 [00:10<00:03, 28.16it/s]\u001b[A\n",
      " 76%|██████████████████████████████▉          | 291/385 [00:10<00:03, 28.51it/s]\u001b[A\n",
      " 33%|█████████████                          | 1251/3753 [02:04<02:59, 13.96it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 297/385 [00:10<00:03, 28.12it/s]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 300/385 [00:10<00:03, 28.05it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 303/385 [00:10<00:02, 28.46it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 306/385 [00:10<00:02, 28.28it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 309/385 [00:10<00:02, 28.18it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 312/385 [00:11<00:02, 27.98it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 315/385 [00:11<00:02, 28.34it/s]\u001b[A\n",
      " 83%|█████████████████████████████████▊       | 318/385 [00:11<00:02, 28.23it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 321/385 [00:11<00:02, 27.71it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 324/385 [00:11<00:02, 27.63it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 327/385 [00:11<00:02, 28.03it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 330/385 [00:11<00:01, 27.85it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▍     | 333/385 [00:11<00:01, 27.82it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 336/385 [00:11<00:01, 27.73it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 339/385 [00:12<00:01, 28.23it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▍    | 342/385 [00:12<00:01, 27.73it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▋    | 345/385 [00:12<00:01, 27.81it/s]\u001b[A\n",
      " 90%|█████████████████████████████████████    | 348/385 [00:12<00:01, 27.78it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 351/385 [00:12<00:01, 28.12it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▋   | 354/385 [00:12<00:01, 27.88it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 357/385 [00:12<00:01, 27.70it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▎  | 360/385 [00:12<00:00, 27.84it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 363/385 [00:12<00:00, 28.35it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 366/385 [00:12<00:00, 28.02it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 369/385 [00:13<00:00, 27.94it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▌ | 372/385 [00:13<00:00, 28.39it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████ | 376/385 [00:13<00:00, 28.98it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 379/385 [00:13<00:00, 29.21it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 382/385 [00:13<00:00, 29.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0843005180358887, 'eval_accuracy': 0.8016234040260315, 'eval_runtime': 14.2923, 'eval_samples_per_second': 215.501, 'eval_steps_per_second': 26.938, 'epoch': 1.0}\n",
      " 33%|█████████████                          | 1251/3753 [02:07<02:59, 13.96it/s]\n",
      "100%|█████████████████████████████████████████| 385/385 [00:13<00:00, 29.47it/s]\u001b[A\n",
      "{'loss': 1.1053, 'learning_rate': 3.0015987210231815e-05, 'epoch': 1.2}         \u001b[A\n",
      " 40%|███████████████▌                       | 1500/3753 [02:26<02:43, 13.74it/s][INFO|trainer.py:2838] 2023-04-19 18:41:19,767 >> Saving model checkpoint to ./run23434/checkpoint-1500\n",
      "{'loss': 0.7445, 'learning_rate': 2.335464961364242e-05, 'epoch': 1.6}          \n",
      " 53%|████████████████████▊                  | 2000/3753 [03:06<02:08, 13.62it/s][INFO|trainer.py:2838] 2023-04-19 18:41:59,546 >> Saving model checkpoint to ./run23434/checkpoint-2000\n",
      "{'loss': 0.5977, 'learning_rate': 1.6693312017053024e-05, 'epoch': 2.0}         \n",
      " 67%|█████████████████████████▉             | 2500/3753 [03:45<01:29, 13.94it/s][INFO|trainer.py:2838] 2023-04-19 18:42:39,265 >> Saving model checkpoint to ./run23434/checkpoint-2500\n",
      " 67%|██████████████████████████             | 2502/3753 [03:48<10:45,  1.94it/s][INFO|trainer.py:762] 2023-04-19 18:42:42,357 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 18:42:42,359 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 18:42:42,359 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 18:42:42,359 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 18:42:42,359 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/385 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                          | 4/385 [00:00<00:10, 37.09it/s]\u001b[A\n",
      "  2%|▉                                          | 8/385 [00:00<00:11, 31.93it/s]\u001b[A\n",
      "  3%|█▎                                        | 12/385 [00:00<00:12, 30.20it/s]\u001b[A\n",
      "  4%|█▋                                        | 16/385 [00:00<00:12, 29.68it/s]\u001b[A\n",
      "  5%|██▏                                       | 20/385 [00:00<00:12, 29.31it/s]\u001b[A\n",
      "  6%|██▌                                       | 24/385 [00:00<00:12, 29.17it/s]\u001b[A\n",
      "  7%|███                                       | 28/385 [00:00<00:12, 29.11it/s]\u001b[A\n",
      "  8%|███▍                                      | 31/385 [00:01<00:12, 29.32it/s]\u001b[A\n",
      "  9%|███▋                                      | 34/385 [00:01<00:12, 29.16it/s]\u001b[A\n",
      " 10%|████                                      | 37/385 [00:01<00:12, 28.95it/s]\u001b[A\n",
      " 10%|████▎                                     | 40/385 [00:01<00:11, 28.80it/s]\u001b[A\n",
      " 11%|████▊                                     | 44/385 [00:01<00:11, 28.86it/s]\u001b[A\n",
      " 12%|█████▏                                    | 48/385 [00:01<00:11, 28.89it/s]\u001b[A\n",
      " 14%|█████▋                                    | 52/385 [00:01<00:11, 28.87it/s]\u001b[A\n",
      " 15%|██████                                    | 56/385 [00:01<00:11, 28.77it/s]\u001b[A\n",
      " 15%|██████▍                                   | 59/385 [00:02<00:11, 28.94it/s]\u001b[A\n",
      " 16%|██████▊                                   | 62/385 [00:02<00:11, 28.74it/s]\u001b[A\n",
      " 17%|███████                                   | 65/385 [00:02<00:11, 28.61it/s]\u001b[A\n",
      " 18%|███████▍                                  | 68/385 [00:02<00:11, 28.37it/s]\u001b[A\n",
      " 18%|███████▋                                  | 71/385 [00:02<00:10, 28.68it/s]\u001b[A\n",
      " 19%|████████                                  | 74/385 [00:02<00:11, 28.24it/s]\u001b[A\n",
      " 20%|████████▍                                 | 77/385 [00:02<00:10, 28.00it/s]\u001b[A\n",
      " 21%|████████▋                                 | 80/385 [00:02<00:10, 28.00it/s]\u001b[A\n",
      " 22%|█████████                                 | 83/385 [00:02<00:10, 28.30it/s]\u001b[A\n",
      " 22%|█████████▍                                | 86/385 [00:02<00:10, 28.24it/s]\u001b[A\n",
      " 23%|█████████▋                                | 89/385 [00:03<00:10, 28.32it/s]\u001b[A\n",
      " 24%|██████████                                | 92/385 [00:03<00:10, 28.41it/s]\u001b[A\n",
      " 25%|██████████▎                               | 95/385 [00:03<00:10, 28.71it/s]\u001b[A\n",
      " 25%|██████████▋                               | 98/385 [00:03<00:10, 28.50it/s]\u001b[A\n",
      " 26%|██████████▊                              | 101/385 [00:03<00:09, 28.46it/s]\u001b[A\n",
      " 27%|███████████                              | 104/385 [00:03<00:09, 28.35it/s]\u001b[A\n",
      " 28%|███████████▍                             | 107/385 [00:03<00:09, 28.71it/s]\u001b[A\n",
      " 29%|███████████▋                             | 110/385 [00:03<00:09, 28.50it/s]\u001b[A\n",
      " 29%|████████████                             | 113/385 [00:03<00:09, 28.20it/s]\u001b[A\n",
      " 30%|████████████▎                            | 116/385 [00:04<00:09, 28.01it/s]\u001b[A\n",
      " 31%|████████████▋                            | 119/385 [00:04<00:09, 28.57it/s]\u001b[A\n",
      " 32%|████████████▉                            | 122/385 [00:04<00:09, 28.47it/s]\u001b[A\n",
      " 32%|█████████████▎                           | 125/385 [00:04<00:09, 28.25it/s]\u001b[A\n",
      " 33%|█████████████▋                           | 128/385 [00:04<00:09, 28.31it/s]\u001b[A\n",
      " 34%|█████████████▉                           | 131/385 [00:04<00:08, 28.64it/s]\u001b[A\n",
      " 35%|██████████████▎                          | 134/385 [00:04<00:08, 28.36it/s]\u001b[A\n",
      " 36%|██████████████▌                          | 137/385 [00:04<00:08, 28.28it/s]\u001b[A\n",
      " 36%|██████████████▉                          | 140/385 [00:04<00:08, 28.29it/s]\u001b[A\n",
      " 37%|███████████████▏                         | 143/385 [00:04<00:08, 28.59it/s]\u001b[A\n",
      " 38%|███████████████▌                         | 146/385 [00:05<00:08, 28.41it/s]\u001b[A\n",
      " 39%|███████████████▊                         | 149/385 [00:05<00:08, 28.38it/s]\u001b[A\n",
      " 39%|████████████████▏                        | 152/385 [00:05<00:08, 28.37it/s]\u001b[A\n",
      " 40%|████████████████▌                        | 155/385 [00:05<00:08, 27.96it/s]\u001b[A\n",
      " 41%|████████████████▊                        | 158/385 [00:05<00:08, 27.82it/s]\u001b[A\n",
      " 42%|█████████████████▏                       | 161/385 [00:05<00:08, 27.83it/s]\u001b[A\n",
      " 43%|█████████████████▍                       | 164/385 [00:05<00:07, 27.98it/s]\u001b[A\n",
      " 43%|█████████████████▊                       | 167/385 [00:05<00:07, 28.42it/s]\u001b[A\n",
      " 44%|██████████████████                       | 170/385 [00:05<00:07, 28.19it/s]\u001b[A\n",
      " 45%|██████████████████▍                      | 173/385 [00:06<00:07, 28.10it/s]\u001b[A\n",
      " 46%|██████████████████▋                      | 176/385 [00:06<00:07, 28.09it/s]\u001b[A\n",
      " 47%|███████████████████▏                     | 180/385 [00:06<00:07, 28.44it/s]\u001b[A\n",
      " 48%|███████████████████▍                     | 183/385 [00:06<00:07, 28.81it/s]\u001b[A\n",
      " 48%|███████████████████▊                     | 186/385 [00:06<00:07, 28.39it/s]\u001b[A\n",
      " 49%|████████████████████▏                    | 189/385 [00:06<00:06, 28.30it/s]\u001b[A\n",
      " 50%|████████████████████▍                    | 192/385 [00:06<00:06, 28.11it/s]\u001b[A\n",
      " 51%|████████████████████▊                    | 195/385 [00:06<00:06, 28.62it/s]\u001b[A\n",
      " 51%|█████████████████████                    | 198/385 [00:06<00:06, 28.60it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 201/385 [00:07<00:06, 28.48it/s]\u001b[A\n",
      " 53%|█████████████████████▋                   | 204/385 [00:07<00:06, 28.29it/s]\u001b[A\n",
      " 54%|██████████████████████                   | 207/385 [00:07<00:06, 28.36it/s]\u001b[A\n",
      " 55%|██████████████████████▎                  | 210/385 [00:07<00:06, 28.30it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 213/385 [00:07<00:06, 28.32it/s]\u001b[A\n",
      " 56%|███████████████████████                  | 216/385 [00:07<00:06, 28.14it/s]\u001b[A\n",
      " 57%|███████████████████████▎                 | 219/385 [00:07<00:05, 28.65it/s]\u001b[A\n",
      " 58%|███████████████████████▋                 | 222/385 [00:07<00:05, 28.63it/s]\u001b[A\n",
      " 58%|███████████████████████▉                 | 225/385 [00:07<00:05, 28.44it/s]\u001b[A\n",
      " 59%|████████████████████████▎                | 228/385 [00:07<00:05, 28.22it/s]\u001b[A\n",
      " 60%|████████████████████████▌                | 231/385 [00:08<00:05, 28.73it/s]\u001b[A\n",
      " 61%|████████████████████████▉                | 234/385 [00:08<00:05, 28.34it/s]\u001b[A\n",
      " 62%|█████████████████████████▏               | 237/385 [00:08<00:05, 27.99it/s]\u001b[A\n",
      " 62%|█████████████████████████▌               | 240/385 [00:08<00:05, 27.90it/s]\u001b[A\n",
      " 63%|█████████████████████████▉               | 243/385 [00:08<00:04, 28.46it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 246/385 [00:08<00:04, 28.34it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 249/385 [00:08<00:04, 28.41it/s]\u001b[A\n",
      " 65%|██████████████████████████▊              | 252/385 [00:08<00:04, 28.33it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 255/385 [00:08<00:04, 28.79it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 258/385 [00:09<00:04, 28.39it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 261/385 [00:09<00:04, 27.99it/s]\u001b[A\n",
      " 69%|████████████████████████████             | 264/385 [00:09<00:04, 27.69it/s]\u001b[A\n",
      " 69%|████████████████████████████▍            | 267/385 [00:09<00:04, 28.02it/s]\u001b[A\n",
      " 70%|████████████████████████████▊            | 270/385 [00:09<00:04, 28.00it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 273/385 [00:09<00:04, 27.85it/s]\u001b[A\n",
      " 72%|█████████████████████████████▍           | 276/385 [00:09<00:03, 27.86it/s]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 280/385 [00:09<00:03, 28.22it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 283/385 [00:09<00:03, 28.41it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 286/385 [00:10<00:03, 28.21it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 289/385 [00:10<00:03, 28.02it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 292/385 [00:10<00:03, 27.90it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 295/385 [00:10<00:03, 28.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 298/385 [00:10<00:03, 28.30it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 301/385 [00:10<00:02, 28.07it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 304/385 [00:10<00:02, 28.24it/s]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 307/385 [00:10<00:02, 28.59it/s]\u001b[A\n",
      " 81%|█████████████████████████████████        | 310/385 [00:10<00:02, 28.38it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 313/385 [00:10<00:02, 28.36it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 316/385 [00:11<00:02, 28.38it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 320/385 [00:11<00:02, 28.47it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 323/385 [00:11<00:02, 28.75it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▋      | 326/385 [00:11<00:02, 28.51it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 329/385 [00:11<00:01, 28.37it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 332/385 [00:11<00:01, 28.41it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 335/385 [00:11<00:01, 28.74it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 338/385 [00:11<00:01, 28.63it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 341/385 [00:11<00:01, 28.28it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 344/385 [00:12<00:01, 28.04it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 347/385 [00:12<00:01, 28.35it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 350/385 [00:12<00:01, 28.18it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 353/385 [00:12<00:01, 28.07it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▉   | 356/385 [00:12<00:01, 27.98it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 359/385 [00:12<00:00, 28.51it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 362/385 [00:12<00:00, 28.35it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 365/385 [00:12<00:00, 28.15it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▏ | 368/385 [00:12<00:00, 27.99it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▌ | 372/385 [00:13<00:00, 28.66it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 375/385 [00:13<00:00, 28.99it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 378/385 [00:13<00:00, 29.08it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 381/385 [00:13<00:00, 28.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5644272565841675, 'eval_accuracy': 0.8775973916053772, 'eval_runtime': 13.5825, 'eval_samples_per_second': 226.762, 'eval_steps_per_second': 28.345, 'epoch': 2.0}\n",
      " 67%|██████████████████████████             | 2502/3753 [04:02<10:45,  1.94it/s]\n",
      "100%|█████████████████████████████████████████| 385/385 [00:13<00:00, 28.52it/s]\u001b[A\n",
      "{'loss': 0.4154, 'learning_rate': 1.003197442046363e-05, 'epoch': 2.4}          \u001b[A\n",
      " 80%|███████████████████████████████▏       | 3000/3753 [04:39<00:54, 13.87it/s][INFO|trainer.py:2838] 2023-04-19 18:43:32,490 >> Saving model checkpoint to ./run23434/checkpoint-3000\n",
      "{'loss': 0.3544, 'learning_rate': 3.370636823874234e-06, 'epoch': 2.8}          \n",
      " 93%|████████████████████████████████████▎  | 3500/3753 [05:18<00:18, 13.72it/s][INFO|trainer.py:2838] 2023-04-19 18:44:12,108 >> Saving model checkpoint to ./run23434/checkpoint-3500\n",
      "100%|███████████████████████████████████████| 3753/3753 [05:40<00:00, 14.20it/s][INFO|trainer.py:762] 2023-04-19 18:44:33,670 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 18:44:33,673 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 18:44:33,673 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 18:44:33,673 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 18:44:33,673 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/385 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                          | 4/385 [00:00<00:10, 37.16it/s]\u001b[A\n",
      "  2%|▉                                          | 8/385 [00:00<00:11, 31.69it/s]\u001b[A\n",
      "  3%|█▎                                        | 12/385 [00:00<00:12, 30.24it/s]\u001b[A\n",
      "  4%|█▋                                        | 16/385 [00:00<00:12, 29.69it/s]\u001b[A\n",
      "  5%|██▏                                       | 20/385 [00:00<00:12, 29.38it/s]\u001b[A\n",
      "  6%|██▌                                       | 24/385 [00:00<00:12, 29.21it/s]\u001b[A\n",
      "  7%|██▉                                       | 27/385 [00:00<00:12, 29.37it/s]\u001b[A\n",
      "  8%|███▎                                      | 30/385 [00:01<00:12, 29.14it/s]\u001b[A\n",
      "  9%|███▌                                      | 33/385 [00:01<00:12, 28.94it/s]\u001b[A\n",
      "  9%|███▉                                      | 36/385 [00:01<00:12, 28.81it/s]\u001b[A\n",
      " 10%|████▎                                     | 40/385 [00:01<00:11, 28.89it/s]\u001b[A\n",
      " 11%|████▊                                     | 44/385 [00:01<00:11, 28.89it/s]\u001b[A\n",
      " 12%|█████▏                                    | 48/385 [00:01<00:11, 28.88it/s]\u001b[A\n",
      " 14%|█████▋                                    | 52/385 [00:01<00:11, 28.98it/s]\u001b[A\n",
      " 15%|██████                                    | 56/385 [00:01<00:11, 28.98it/s]\u001b[A\n",
      " 16%|██████▌                                   | 60/385 [00:02<00:11, 28.95it/s]\u001b[A\n",
      " 16%|██████▊                                   | 63/385 [00:02<00:11, 29.06it/s]\u001b[A\n",
      " 17%|███████▏                                  | 66/385 [00:02<00:11, 28.80it/s]\u001b[A\n",
      " 18%|███████▌                                  | 69/385 [00:02<00:11, 28.65it/s]\u001b[A\n",
      " 19%|███████▊                                  | 72/385 [00:02<00:11, 28.40it/s]\u001b[A\n",
      " 19%|████████▏                                 | 75/385 [00:02<00:10, 28.79it/s]\u001b[A\n",
      " 20%|████████▌                                 | 78/385 [00:02<00:10, 28.43it/s]\u001b[A\n",
      " 21%|████████▊                                 | 81/385 [00:02<00:10, 28.19it/s]\u001b[A\n",
      " 22%|█████████▏                                | 84/385 [00:02<00:10, 28.00it/s]\u001b[A\n",
      " 23%|█████████▌                                | 88/385 [00:03<00:10, 28.31it/s]\u001b[A\n",
      " 24%|█████████▉                                | 91/385 [00:03<00:10, 28.69it/s]\u001b[A\n",
      " 24%|██████████▎                               | 94/385 [00:03<00:10, 28.50it/s]\u001b[A\n",
      " 25%|██████████▌                               | 97/385 [00:03<00:10, 28.35it/s]\u001b[A\n",
      " 26%|██████████▋                              | 100/385 [00:03<00:10, 27.43it/s]\u001b[A\n",
      " 27%|██████████▉                              | 103/385 [00:03<00:10, 27.77it/s]\u001b[A\n",
      " 28%|███████████▎                             | 106/385 [00:03<00:10, 27.85it/s]\u001b[A\n",
      " 28%|███████████▌                             | 109/385 [00:03<00:09, 27.90it/s]\u001b[A\n",
      " 29%|███████████▉                             | 112/385 [00:03<00:09, 28.06it/s]\u001b[A\n",
      " 30%|████████████▏                            | 115/385 [00:03<00:09, 28.55it/s]\u001b[A\n",
      " 31%|████████████▌                            | 118/385 [00:04<00:09, 28.51it/s]\u001b[A\n",
      " 31%|████████████▉                            | 121/385 [00:04<00:09, 28.07it/s]\u001b[A\n",
      " 32%|█████████████▏                           | 124/385 [00:04<00:09, 28.21it/s]\u001b[A\n",
      " 33%|█████████████▌                           | 127/385 [00:04<00:09, 28.44it/s]\u001b[A\n",
      " 34%|█████████████▊                           | 130/385 [00:04<00:09, 28.28it/s]\u001b[A\n",
      " 35%|██████████████▏                          | 133/385 [00:04<00:08, 28.10it/s]\u001b[A\n",
      " 35%|██████████████▍                          | 136/385 [00:04<00:08, 27.89it/s]\u001b[A\n",
      " 36%|██████████████▊                          | 139/385 [00:04<00:08, 28.40it/s]\u001b[A\n",
      " 37%|███████████████                          | 142/385 [00:04<00:08, 28.15it/s]\u001b[A\n",
      " 38%|███████████████▍                         | 145/385 [00:05<00:08, 28.01it/s]\u001b[A\n",
      " 38%|███████████████▊                         | 148/385 [00:05<00:08, 27.97it/s]\u001b[A\n",
      " 39%|████████████████                         | 151/385 [00:05<00:08, 28.49it/s]\u001b[A\n",
      " 40%|████████████████▍                        | 154/385 [00:05<00:08, 28.30it/s]\u001b[A\n",
      " 41%|████████████████▋                        | 157/385 [00:05<00:08, 28.00it/s]\u001b[A\n",
      " 42%|█████████████████                        | 160/385 [00:05<00:08, 28.06it/s]\u001b[A\n",
      " 42%|█████████████████▎                       | 163/385 [00:05<00:07, 28.58it/s]\u001b[A\n",
      " 43%|█████████████████▋                       | 166/385 [00:05<00:07, 28.37it/s]\u001b[A\n",
      " 44%|█████████████████▉                       | 169/385 [00:05<00:07, 28.13it/s]\u001b[A\n",
      " 45%|██████████████████▎                      | 172/385 [00:06<00:07, 28.20it/s]\u001b[A\n",
      " 45%|██████████████████▋                      | 175/385 [00:06<00:07, 28.43it/s]\u001b[A\n",
      " 46%|██████████████████▉                      | 178/385 [00:06<00:07, 28.30it/s]\u001b[A\n",
      " 47%|███████████████████▎                     | 181/385 [00:06<00:07, 27.98it/s]\u001b[A\n",
      " 48%|███████████████████▌                     | 184/385 [00:06<00:07, 28.20it/s]\u001b[A\n",
      " 49%|███████████████████▉                     | 187/385 [00:06<00:06, 28.68it/s]\u001b[A\n",
      " 49%|████████████████████▏                    | 190/385 [00:06<00:06, 28.57it/s]\u001b[A\n",
      " 50%|████████████████████▌                    | 193/385 [00:06<00:06, 28.35it/s]\u001b[A\n",
      " 51%|████████████████████▊                    | 196/385 [00:06<00:06, 28.41it/s]\u001b[A\n",
      " 52%|█████████████████████▏                   | 199/385 [00:06<00:06, 28.76it/s]\u001b[A\n",
      " 52%|█████████████████████▌                   | 202/385 [00:07<00:06, 28.54it/s]\u001b[A\n",
      " 53%|█████████████████████▊                   | 205/385 [00:07<00:06, 28.37it/s]\u001b[A\n",
      " 54%|██████████████████████▏                  | 208/385 [00:07<00:06, 27.90it/s]\u001b[A\n",
      " 55%|██████████████████████▍                  | 211/385 [00:07<00:06, 28.48it/s]\u001b[A\n",
      " 56%|██████████████████████▊                  | 214/385 [00:07<00:06, 28.24it/s]\u001b[A\n",
      " 56%|███████████████████████                  | 217/385 [00:07<00:05, 28.10it/s]\u001b[A\n",
      " 57%|███████████████████████▍                 | 220/385 [00:07<00:05, 27.96it/s]\u001b[A\n",
      " 58%|███████████████████████▋                 | 223/385 [00:07<00:05, 28.31it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 226/385 [00:07<00:05, 28.31it/s]\u001b[A\n",
      " 59%|████████████████████████▍                | 229/385 [00:08<00:05, 28.22it/s]\u001b[A\n",
      " 60%|████████████████████████▋                | 232/385 [00:08<00:05, 28.24it/s]\u001b[A\n",
      " 61%|█████████████████████████                | 235/385 [00:08<00:05, 27.18it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 238/385 [00:08<00:05, 27.16it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 241/385 [00:08<00:05, 27.31it/s]\u001b[A\n",
      " 63%|█████████████████████████▉               | 244/385 [00:08<00:05, 27.60it/s]\u001b[A\n",
      " 64%|██████████████████████████▎              | 247/385 [00:08<00:04, 28.24it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 250/385 [00:08<00:04, 28.22it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 253/385 [00:08<00:04, 27.96it/s]\u001b[A\n",
      " 66%|███████████████████████████▎             | 256/385 [00:09<00:04, 27.85it/s]\u001b[A\n",
      " 67%|███████████████████████████▌             | 259/385 [00:09<00:04, 28.37it/s]\u001b[A\n",
      " 68%|███████████████████████████▉             | 262/385 [00:09<00:04, 28.22it/s]\u001b[A\n",
      " 69%|████████████████████████████▏            | 265/385 [00:09<00:04, 27.88it/s]\u001b[A\n",
      " 70%|████████████████████████████▌            | 268/385 [00:09<00:04, 27.52it/s]\u001b[A\n",
      " 70%|████████████████████████████▊            | 271/385 [00:09<00:04, 28.10it/s]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 274/385 [00:09<00:03, 28.04it/s]\u001b[A\n",
      " 72%|█████████████████████████████▍           | 277/385 [00:09<00:03, 27.86it/s]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 280/385 [00:09<00:03, 27.93it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 283/385 [00:09<00:03, 28.39it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 286/385 [00:10<00:03, 28.48it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 289/385 [00:10<00:03, 28.40it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 292/385 [00:10<00:03, 28.16it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 295/385 [00:10<00:03, 28.69it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 298/385 [00:10<00:03, 28.65it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 301/385 [00:10<00:02, 28.40it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 304/385 [00:10<00:02, 28.35it/s]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 307/385 [00:10<00:02, 28.67it/s]\u001b[A\n",
      " 81%|█████████████████████████████████        | 310/385 [00:10<00:02, 28.51it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 313/385 [00:11<00:02, 28.39it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 316/385 [00:11<00:02, 28.29it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 320/385 [00:11<00:02, 28.60it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 323/385 [00:11<00:02, 28.95it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▋      | 326/385 [00:11<00:02, 28.41it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 329/385 [00:11<00:01, 28.22it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 332/385 [00:11<00:01, 28.26it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 335/385 [00:11<00:01, 28.65it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 338/385 [00:11<00:01, 28.35it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 341/385 [00:12<00:01, 28.12it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 344/385 [00:12<00:01, 28.12it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 347/385 [00:12<00:01, 28.56it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 350/385 [00:12<00:01, 28.42it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 353/385 [00:12<00:01, 28.16it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▉   | 356/385 [00:12<00:01, 28.08it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 359/385 [00:12<00:00, 28.42it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 362/385 [00:12<00:00, 28.37it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 365/385 [00:12<00:00, 28.32it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▏ | 368/385 [00:12<00:00, 28.21it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 371/385 [00:13<00:00, 28.61it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 374/385 [00:13<00:00, 28.96it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 377/385 [00:13<00:00, 29.11it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 380/385 [00:13<00:00, 29.08it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.45605555176734924, 'eval_accuracy': 0.8951298594474792, 'eval_runtime': 13.619, 'eval_samples_per_second': 226.154, 'eval_steps_per_second': 28.269, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 3753/3753 [05:53<00:00, 14.20it/s]\n",
      "100%|█████████████████████████████████████████| 385/385 [00:13<00:00, 29.43it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2039] 2023-04-19 18:44:47,304 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 353.9384, 'train_samples_per_second': 84.786, 'train_steps_per_second': 10.604, 'train_loss': 1.174913464817339, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 3753/3753 [05:53<00:00, 10.60it/s]\n",
      "[INFO|trainer.py:2838] 2023-04-19 18:44:47,384 >> Saving model checkpoint to ./run23434\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     1.1749\n",
      "  train_runtime            = 0:05:53.93\n",
      "  train_samples            =      10003\n",
      "  train_samples_per_second =     84.786\n",
      "  train_steps_per_second   =     10.604\n",
      "[INFO|trainer.py:762] 2023-04-19 18:44:48,483 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 18:44:48,485 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 18:44:48,485 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 18:44:48,485 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 18:44:48,485 >>   Batch size = 8\n",
      "100%|█████████████████████████████████████████| 385/385 [00:13<00:00, 28.98it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.8951\n",
      "  eval_loss               =     0.4561\n",
      "  eval_runtime            = 0:00:13.33\n",
      "  eval_samples            =       3080\n",
      "  eval_samples_per_second =    230.934\n",
      "  eval_steps_per_second   =     28.867\n"
     ]
    }
   ],
   "source": [
    "!CUSTOM_CACHE_REPO=philschmid/neuron-cache python3 scripts/run_glue.py  --model_name_or_path bert-base-cased --per_device_train_batch_size 8 --do_train True --do_eval True --dataset_name banking77 --evaluation_strategy \"epoch\" --output_dir ./run23434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab8531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112abfe8",
   "metadata": {},
   "source": [
    "# Distrubted test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4bc7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -r /var/tmp/neuron-compile-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1617e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "WARNING:__main__:Process rank: 1, device: xla:0, n_gpu: 0distributed training: True, 16-bits training: False\n",
      "WARNING:__main__:Process rank: 0, device: xla:1, n_gpu: 0distributed training: True, 16-bits training: False\n",
      "/home/ubuntu/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n",
      "WARNING:datasets.builder:Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 690.36it/s]\n",
      "/home/ubuntu/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n",
      "WARNING:datasets.builder:Found cached dataset banking77 (/home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 709.34it/s]\n",
      "[WARNING|modeling_utils.py:3180] 2023-04-19 19:29:13,763 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3192] 2023-04-19 19:29:13,763 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-8a4bef8cbb7d2d6c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-a6ccd2cfc828d15a.arrow\n",
      "[WARNING|modeling_utils.py:3180] 2023-04-19 19:29:13,858 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3192] 2023-04-19 19:29:13,858 >> Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-8a4bef8cbb7d2d6c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/cache-a6ccd2cfc828d15a.arrow\n",
      "[INFO|trainer.py:762] 2023-04-19 19:29:18,223 >> The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainers.py:119] 2023-04-19 19:29:18,228 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:1769] 2023-04-19 19:29:18,229 >> ***** Running training *****\n",
      "[INFO|trainer.py:1770] 2023-04-19 19:29:18,229 >>   Num examples = 10,003\n",
      "[INFO|trainer.py:1771] 2023-04-19 19:29:18,229 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1772] 2023-04-19 19:29:18,229 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1773] 2023-04-19 19:29:18,229 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1774] 2023-04-19 19:29:18,229 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1775] 2023-04-19 19:29:18,229 >>   Total optimization steps = 1,878\n",
      "[INFO|trainer.py:1776] 2023-04-19 19:29:18,230 >>   Number of trainable parameters = 108,369,485\n",
      "  0%|                                                  | 0/1878 [00:00<?, ?it/s]2023-04-19 19:29:18.000315: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13512489239619371125.\n",
      "2023-04-19 19:29:18.000315: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13512489239619371125/MODULE_0_SyncTensorsGraph.206_13512489239619371125_ip-172-31-79-164-213a19c-1224654-5f9b570ac1427/de1a44e8-be21-406e-b351-664c14c8eda0\n",
      ".\n",
      "Compiler status PASS\n",
      "2023-04-19 19:29:21.000673: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "  0%|                                        | 1/1878 [00:05<3:02:04,  5.82s/it]2023-04-19 19:29:25.000156: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8884703837403786447.\n",
      "2023-04-19 19:29:25.000157: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8884703837403786447/MODULE_1_SyncTensorsGraph.22421_8884703837403786447_ip-172-31-79-164-213a19c-1224654-5f9b571147707/5375f9e5-6f73-41bf-b41d-31c1dd8a6b55\n",
      "............\n",
      "Compiler status PASS\n",
      "2023-04-19 19:33:09.000679: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "2023-Apr-19 19:33:10.0694 1224654:1224675 [1] ofi_init:1453 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2023-Apr-19 19:33:10.0694 1224654:1224675 [1] init.cc:101 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "  0%|                                      | 2/1878 [03:52<70:45:20, 135.78s/it]2023-04-19 19:33:13.000784: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_15791204366224688364.\n",
      "2023-04-19 19:33:13.000785: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_15791204366224688364/MODULE_2_SyncTensorsGraph.22421_15791204366224688364_ip-172-31-79-164-65e89b62-1224654-5f9b57eb50656/4ee1af84-f869-4413-854e-b279dd6d7ef6\n",
      ".............\n",
      "Compiler status PASS\n",
      "2023-04-19 19:37:31.000193: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      " 27%|██████████▋                             | 499/1878 [09:11<02:28,  9.30it/s]2023-04-19 19:38:30.000266: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_569571592325889951/MODULE_3_SyncTensorsGraph.4_569571592325889951_ip-172-31-79-164-e0e2b523-1925-5f9b0c6d4836a/d5102952-8c17-4750-ab95-99cb0b457fa4/MODULE_3_SyncTensorsGraph.4_569571592325889951_ip-172-31-79-164-e0e2b523-1925-5f9b0c6d4836a.neff. Exiting with a successfully compiled graph\n",
      "2023-04-19 19:38:30.000345: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_11812976703327707322/MODULE_4_SyncTensorsGraph.21_11812976703327707322_ip-172-31-79-164-6964ff58-1925-5f9b0c6fae33b/0ab39f6c-b3c5-4636-9f3a-53bf0a41c246/MODULE_4_SyncTensorsGraph.21_11812976703327707322_ip-172-31-79-164-6964ff58-1925-5f9b0c6fae33b.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 2.048, 'learning_rate': 3.668796592119276e-05, 'epoch': 0.8}           \n",
      " 27%|██████████▋                             | 500/1878 [09:12<02:28,  9.30it/s]2023-04-19 19:38:30.000529: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8601779472828624277.\n",
      "2023-04-19 19:38:30.000529: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_8601779472828624277/MODULE_5_SyncTensorsGraph.31_8601779472828624277_ip-172-31-79-164-b4aca2eb-1224654-5f9b591962ecc/927e669e-cd54-4074-a9a8-92a6b35331f4\n",
      ".\n",
      "Compiler status PASS\n",
      "2023-04-19 19:38:32.000978: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "[INFO|trainer.py:2838] 2023-04-19 19:38:33,139 >> Saving model checkpoint to ./bf16/checkpoint-500\n",
      "2023-04-19 19:38:37.000019: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_931450859643720011/MODULE_5_SyncTensorsGraph.6_931450859643720011_ip-172-31-79-164-30d56256-1925-5f9b0c7235cc9/d4d05f89-f323-4612-b387-52760c9f1da5/MODULE_5_SyncTensorsGraph.6_931450859643720011_ip-172-31-79-164-30d56256-1925-5f9b0c7235cc9.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_0_SyncTensorsGraph.206_13512489239619371125_213a19c-1224654-5f9b570ac1427\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.80it/s]\u001b[A\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/71dc3cf993a8559223379c5d891cb0bb9d0ac83f3f17b5cc91c319f727f05ecde6560378f7611e08c59d18228c4350efe5da75b8194193167c216d199eee4b22/514ec0f125b2cc1773bf0836bb0a14cf36714d85c023671a8fde8eae0267b4d239002ad425ddc4899d9639f4f8d7b3a90e4d10c6df9a2b09c04cfeec8c283ec9/MODULE_13512489239619371125/MODULE_0_SyncTensorsGraph.206_13512489239619371125_ip-172-31-79-164-213a19c-1224654-5f9b570ac1427/de1a44e8-be21-406e-b351-664c14c8eda0/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_1_SyncTensorsGraph.22421_8884703837403786447_213a19c-1224654-5f9b57114770\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  5.20it/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_1_SyncTensorsGraph.22421_8884703837403786447_213a19c-1224654-5f9b57114770\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\u001b[A\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/71dc3cf993a8559223379c5d891cb0bb9d0ac83f3f17b5cc91c319f727f05ecde6560378f7611e08c59d18228c4350efe5da75b8194193167c216d199eee4b22/514ec0f125b2cc1773bf0836bb0a14cf36714d85c023671a8fde8eae0267b4d239002ad425ddc4899d9639f4f8d7b3a90e4d10c6df9a2b09c04cfeec8c283ec9/MODULE_8884703837403786447/MODULE_1_SyncTensorsGraph.22421_8884703837403786447_ip-172-31-79-164-213a19c-1224654-5f9b571147707/5375f9e5-6f73-41bf-b41d-31c1dd8a6b55/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_2_SyncTensorsGraph.22421_15791204366224688364_65e89b62-1224654-5f9b57eb50\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\u001b[A\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/71dc3cf993a8559223379c5d891cb0bb9d0ac83f3f17b5cc91c319f727f05ecde6560378f7611e08c59d18228c4350efe5da75b8194193167c216d199eee4b22/514ec0f125b2cc1773bf0836bb0a14cf36714d85c023671a8fde8eae0267b4d239002ad425ddc4899d9639f4f8d7b3a90e4d10c6df9a2b09c04cfeec8c283ec9/MODULE_15791204366224688364/MODULE_2_SyncTensorsGraph.22421_15791204366224688364_ip-172-31-79-164-65e89b62-1224654-5f9b57eb50656/4ee1af84-f869-4413-854e-b279dd6d7ef6/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_2_SyncTensorsGraph.22421_15791204366224688364_65e89b62-1224654-5f9b57eb50\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\u001b[A\n",
      " 33%|█████████████▎                          | 626/1878 [09:37<01:44, 12.01it/s][INFO|trainer.py:762] 2023-04-19 19:38:55,312 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 19:38:55,315 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 19:38:55,315 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 19:38:55,315 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 19:38:55,315 >>   Batch size = 8\n",
      "2023-04-19 19:38:55.000550: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_7972356675706026174.\n",
      "2023-04-19 19:38:55.000551: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_7972356675706026174/MODULE_7_SyncTensorsGraph.4548_7972356675706026174_ip-172-31-79-164-a87cffc2-1224654-5f9b59313fd0c/1a77f80d-e184-492a-926f-26381f3aba86\n",
      " 33%|█████████████▎                          | 626/1878 [09:54<01:44, 12.01it/s]..\n",
      "Compiler status PASS\n",
      "2023-04-19 19:39:39.000203: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "2023-04-19 19:39:39.000528: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13837218930383410181/MODULE_7_SyncTensorsGraph.4_13837218930383410181_ip-172-31-79-164-9c5ec96f-1925-5f9b0ccb625b9/69c18272-ae7f-49ab-9342-b83e907f2f3d/MODULE_7_SyncTensorsGraph.4_13837218930383410181_ip-172-31-79-164-9c5ec96f-1925-5f9b0ccb625b9.neff. Exiting with a successfully compiled graph\n",
      "2023-04-19 19:39:39.000603: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpyzgige81/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_8_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-dfdb1411-1925-5f9b0ccdd1999/1f482008-402e-4360-9218-0242bc4049f0/MODULE_8_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-dfdb1411-1925-5f9b0ccdd1999.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▋                                          | 3/193 [00:00<00:07, 23.77it/s]\u001b[A\n",
      "  3%|█▎                                         | 6/193 [00:00<00:09, 19.30it/s]\u001b[A\n",
      "  4%|█▊                                         | 8/193 [00:00<00:09, 18.91it/s]\u001b[A\n",
      "  5%|██▏                                       | 10/193 [00:00<00:09, 19.02it/s]\u001b[A\n",
      "  6%|██▌                                       | 12/193 [00:00<00:09, 18.46it/s]\u001b[A\n",
      "  7%|███                                       | 14/193 [00:00<00:09, 18.61it/s]\u001b[A\n",
      "  8%|███▍                                      | 16/193 [00:00<00:09, 18.19it/s]\u001b[A\n",
      "  9%|███▉                                      | 18/193 [00:00<00:09, 18.22it/s]\u001b[A\n",
      " 10%|████▎                                     | 20/193 [00:01<00:09, 17.63it/s]\u001b[A\n",
      " 11%|████▊                                     | 22/193 [00:01<00:09, 17.50it/s]\u001b[A\n",
      " 12%|█████▏                                    | 24/193 [00:01<00:09, 17.36it/s]\u001b[A\n",
      " 13%|█████▋                                    | 26/193 [00:01<00:09, 17.87it/s]\u001b[A\n",
      " 15%|██████                                    | 28/193 [00:01<00:09, 17.75it/s]\u001b[A\n",
      " 16%|██████▌                                   | 30/193 [00:01<00:09, 17.82it/s]\u001b[A\n",
      " 17%|██████▉                                   | 32/193 [00:01<00:09, 17.82it/s]\u001b[A\n",
      " 18%|███████▍                                  | 34/193 [00:01<00:09, 17.54it/s]\u001b[A\n",
      " 19%|███████▊                                  | 36/193 [00:02<00:09, 16.99it/s]\u001b[A\n",
      " 20%|████████▎                                 | 38/193 [00:02<00:09, 16.93it/s]\u001b[A\n",
      " 21%|████████▋                                 | 40/193 [00:02<00:09, 16.80it/s]\u001b[A\n",
      " 22%|█████████▏                                | 42/193 [00:02<00:08, 17.31it/s]\u001b[A\n",
      " 23%|█████████▊                                | 45/193 [00:02<00:07, 18.60it/s]\u001b[A\n",
      " 25%|██████████▍                               | 48/193 [00:02<00:07, 19.35it/s]\u001b[A\n",
      " 26%|██████████▉                               | 50/193 [00:02<00:07, 19.23it/s]\u001b[A\n",
      " 27%|███████████▎                              | 52/193 [00:02<00:07, 19.36it/s]\u001b[A\n",
      " 28%|███████████▉                              | 55/193 [00:02<00:06, 20.37it/s]\u001b[A\n",
      " 30%|████████████▌                             | 58/193 [00:03<00:06, 21.06it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 61/193 [00:03<00:06, 21.32it/s]\u001b[A\n",
      " 33%|█████████████▉                            | 64/193 [00:03<00:05, 21.52it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 67/193 [00:03<00:05, 22.22it/s]\u001b[A\n",
      " 36%|███████████████▏                          | 70/193 [00:03<00:05, 22.65it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 73/193 [00:03<00:05, 20.94it/s]\u001b[A\n",
      " 39%|████████████████▌                         | 76/193 [00:03<00:06, 19.36it/s]\u001b[A\n",
      " 40%|████████████████▉                         | 78/193 [00:04<00:05, 19.17it/s]\u001b[A\n",
      " 41%|█████████████████▍                        | 80/193 [00:04<00:06, 18.54it/s]\u001b[A\n",
      " 42%|█████████████████▊                        | 82/193 [00:04<00:05, 18.85it/s]\u001b[A\n",
      " 44%|██████████████████▎                       | 84/193 [00:04<00:05, 18.18it/s]\u001b[A\n",
      " 45%|██████████████████▋                       | 86/193 [00:04<00:05, 17.84it/s]\u001b[A\n",
      " 46%|███████████████████▏                      | 88/193 [00:04<00:05, 17.87it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 91/193 [00:04<00:05, 18.99it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 93/193 [00:04<00:05, 18.66it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:05<00:05, 18.60it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 97/193 [00:05<00:05, 17.78it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 99/193 [00:05<00:05, 17.70it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:05<00:05, 18.05it/s]\u001b[A\n",
      " 54%|██████████████████████                   | 104/193 [00:05<00:05, 17.77it/s]\u001b[A\n",
      " 55%|██████████████████████▌                  | 106/193 [00:05<00:05, 17.38it/s]\u001b[A\n",
      " 56%|██████████████████████▉                  | 108/193 [00:05<00:05, 17.00it/s]\u001b[A\n",
      " 57%|███████████████████████▎                 | 110/193 [00:05<00:04, 17.44it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:06<00:04, 18.69it/s]\u001b[A\n",
      " 60%|████████████████████████▋                | 116/193 [00:06<00:03, 19.78it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:06<00:03, 20.91it/s]\u001b[A\n",
      " 63%|█████████████████████████▉               | 122/193 [00:06<00:03, 21.30it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:06<00:03, 20.96it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 128/193 [00:06<00:03, 20.95it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:06<00:02, 21.39it/s]\u001b[A\n",
      " 69%|████████████████████████████▍            | 134/193 [00:06<00:02, 21.97it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:07<00:02, 22.22it/s]\u001b[A\n",
      " 73%|█████████████████████████████▋           | 140/193 [00:07<00:02, 21.64it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:07<00:02, 20.93it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 146/193 [00:07<00:02, 20.61it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:07<00:02, 20.21it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 152/193 [00:07<00:02, 19.30it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:08<00:01, 19.79it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 157/193 [00:08<00:01, 19.79it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 159/193 [00:08<00:01, 19.64it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:08<00:01, 19.44it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 163/193 [00:08<00:01, 19.32it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 165/193 [00:08<00:01, 19.08it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:08<00:01, 19.03it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 169/193 [00:08<00:01, 18.65it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 171/193 [00:08<00:01, 18.80it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 174/193 [00:09<00:00, 19.89it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 177/193 [00:09<00:00, 20.40it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 180/193 [00:09<00:00, 20.36it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 183/193 [00:09<00:00, 21.11it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 186/193 [00:09<00:00, 20.09it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 189/193 [00:09<00:00, 19.44it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 191/193 [00:09<00:00, 19.11it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.5324676036834717, 'eval_accuracy': 0.614935040473938, 'eval_runtime': 54.311, 'eval_samples_per_second': 56.71, 'eval_steps_per_second': 3.554, 'epoch': 1.0}\n",
      " 33%|█████████████▎                          | 626/1878 [10:31<01:44, 12.01it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:10<00:00, 18.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_5_SyncTensorsGraph.31_8601779472828624277_b4aca2eb-1224654-5f9b591962ecc.\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  6.92it/s]\u001b[A\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/71dc3cf993a8559223379c5d891cb0bb9d0ac83f3f17b5cc91c319f727f05ecde6560378f7611e08c59d18228c4350efe5da75b8194193167c216d199eee4b22/514ec0f125b2cc1773bf0836bb0a14cf36714d85c023671a8fde8eae0267b4d239002ad425ddc4899d9639f4f8d7b3a90e4d10c6df9a2b09c04cfeec8c283ec9/MODULE_8601779472828624277/MODULE_5_SyncTensorsGraph.31_8601779472828624277_ip-172-31-79-164-b4aca2eb-1224654-5f9b591962ecc/927e669e-cd54-4074-a9a8-92a6b35331f4/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_7_SyncTensorsGraph.4548_7972356675706026174_a87cffc2-1224654-5f9b59313fd0\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\u001b[A\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/71dc3cf993a8559223379c5d891cb0bb9d0ac83f3f17b5cc91c319f727f05ecde6560378f7611e08c59d18228c4350efe5da75b8194193167c216d199eee4b22/514ec0f125b2cc1773bf0836bb0a14cf36714d85c023671a8fde8eae0267b4d239002ad425ddc4899d9639f4f8d7b3a90e4d10c6df9a2b09c04cfeec8c283ec9/MODULE_7972356675706026174/MODULE_7_SyncTensorsGraph.4548_7972356675706026174_ip-172-31-79-164-a87cffc2-1224654-5f9b59313fd0c/1a77f80d-e184-492a-926f-26381f3aba86/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "MODULE_7_SyncTensorsGraph.4548_7972356675706026174_a87cffc2-1224654-5f9b59313fd0\u001b[A\u001b[A\n",
      "\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  3.45it/s]\u001b[A\n",
      "{'loss': 2.048, 'learning_rate': 2.3375931842385517e-05, 'epoch': 1.6}          \n",
      " 53%|████████████████████▊                  | 1000/1878 [11:13<01:15, 11.63it/s][INFO|trainer.py:2838] 2023-04-19 19:40:31,423 >> Saving model checkpoint to ./bf16/checkpoint-1000\n",
      " 67%|█████████████████████████▉             | 1251/1878 [11:38<00:52, 11.84it/s][INFO|trainer.py:762] 2023-04-19 19:40:56,587 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 19:40:56,589 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 19:40:56,589 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 19:40:56,589 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 19:40:56,589 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                          | 4/193 [00:00<00:05, 32.16it/s]\u001b[A\n",
      "  4%|█▊                                         | 8/193 [00:00<00:06, 27.89it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/193 [00:00<00:06, 27.80it/s]\u001b[A\n",
      "  7%|███                                       | 14/193 [00:00<00:06, 27.10it/s]\u001b[A\n",
      "  9%|███▋                                      | 17/193 [00:00<00:06, 26.66it/s]\u001b[A\n",
      " 10%|████▎                                     | 20/193 [00:00<00:06, 26.44it/s]\u001b[A\n",
      " 12%|█████                                     | 23/193 [00:00<00:06, 26.77it/s]\u001b[A\n",
      " 13%|█████▋                                    | 26/193 [00:00<00:06, 26.40it/s]\u001b[A\n",
      " 15%|██████▎                                   | 29/193 [00:01<00:06, 25.67it/s]\u001b[A\n",
      " 17%|██████▉                                   | 32/193 [00:01<00:06, 25.59it/s]\u001b[A\n",
      " 18%|███████▌                                  | 35/193 [00:01<00:06, 26.11it/s]\u001b[A\n",
      " 20%|████████▎                                 | 38/193 [00:01<00:06, 25.69it/s]\u001b[A\n",
      " 21%|████████▉                                 | 41/193 [00:01<00:05, 25.63it/s]\u001b[A\n",
      " 23%|█████████▌                                | 44/193 [00:01<00:05, 25.27it/s]\u001b[A\n",
      " 24%|██████████▏                               | 47/193 [00:01<00:05, 25.33it/s]\u001b[A\n",
      " 26%|██████████▉                               | 50/193 [00:01<00:05, 24.79it/s]\u001b[A\n",
      " 27%|███████████▌                              | 53/193 [00:02<00:05, 25.02it/s]\u001b[A\n",
      " 29%|████████████▏                             | 56/193 [00:02<00:05, 24.96it/s]\u001b[A\n",
      " 31%|████████████▊                             | 59/193 [00:02<00:05, 25.65it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 62/193 [00:02<00:05, 25.66it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 65/193 [00:02<00:04, 25.70it/s]\u001b[A\n",
      " 35%|██████████████▊                           | 68/193 [00:02<00:04, 25.77it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 71/193 [00:02<00:04, 26.26it/s]\u001b[A\n",
      " 38%|████████████████                          | 74/193 [00:02<00:04, 25.75it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 77/193 [00:02<00:04, 25.75it/s]\u001b[A\n",
      " 41%|█████████████████▍                        | 80/193 [00:03<00:04, 25.74it/s]\u001b[A\n",
      " 43%|██████████████████                        | 83/193 [00:03<00:04, 26.17it/s]\u001b[A\n",
      " 45%|██████████████████▋                       | 86/193 [00:03<00:04, 25.82it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 89/193 [00:03<00:04, 25.84it/s]\u001b[A\n",
      " 48%|████████████████████                      | 92/193 [00:03<00:03, 25.89it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:03<00:03, 26.35it/s]\u001b[A\n",
      " 51%|█████████████████████▎                    | 98/193 [00:03<00:03, 26.15it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:03<00:03, 25.87it/s]\u001b[A\n",
      " 54%|██████████████████████                   | 104/193 [00:04<00:03, 25.84it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 107/193 [00:04<00:03, 26.31it/s]\u001b[A\n",
      " 57%|███████████████████████▎                 | 110/193 [00:04<00:03, 26.24it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:04<00:03, 26.14it/s]\u001b[A\n",
      " 60%|████████████████████████▋                | 116/193 [00:04<00:02, 26.11it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:04<00:02, 26.57it/s]\u001b[A\n",
      " 63%|█████████████████████████▉               | 122/193 [00:04<00:02, 26.30it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:04<00:02, 25.37it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 128/193 [00:04<00:02, 23.81it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:05<00:02, 23.41it/s]\u001b[A\n",
      " 69%|████████████████████████████▍            | 134/193 [00:05<00:02, 23.92it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:05<00:02, 24.33it/s]\u001b[A\n",
      " 73%|█████████████████████████████▋           | 140/193 [00:05<00:02, 24.76it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:05<00:02, 24.87it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 146/193 [00:05<00:01, 24.98it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:05<00:01, 24.26it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 152/193 [00:05<00:01, 24.02it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:06<00:01, 24.55it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 158/193 [00:06<00:01, 24.80it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:06<00:01, 23.99it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 164/193 [00:06<00:01, 23.86it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:06<00:01, 24.81it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 170/193 [00:06<00:00, 25.09it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 173/193 [00:06<00:00, 23.72it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 176/193 [00:06<00:00, 23.35it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 179/193 [00:07<00:00, 24.46it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 182/193 [00:07<00:00, 24.46it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 185/193 [00:07<00:00, 24.95it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 188/193 [00:07<00:00, 24.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.1903815269470215, 'eval_accuracy': 0.6626623272895813, 'eval_runtime': 7.6616, 'eval_samples_per_second': 402.007, 'eval_steps_per_second': 25.191, 'epoch': 2.0}\n",
      " 67%|██████████████████████████             | 1252/1878 [11:46<00:52, 11.84it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:07<00:00, 25.24it/s]\u001b[A\n",
      "{'loss': 2.048, 'learning_rate': 1.0063897763578276e-05, 'epoch': 2.4}          \u001b[A\n",
      " 80%|███████████████████████████████▏       | 1500/1878 [12:07<00:32, 11.65it/s][INFO|trainer.py:2838] 2023-04-19 19:41:25,557 >> Saving model checkpoint to ./bf16/checkpoint-1500\n",
      "100%|██████████████████████████████████████▉| 1877/1878 [12:42<00:00, 12.36it/s][INFO|trainer.py:762] 2023-04-19 19:42:00,936 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 19:42:00,938 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 19:42:00,938 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 19:42:00,938 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 19:42:00,938 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                          | 4/193 [00:00<00:05, 33.41it/s]\u001b[A\n",
      "  4%|█▊                                         | 8/193 [00:00<00:06, 28.68it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/193 [00:00<00:07, 25.57it/s]\u001b[A\n",
      "  7%|███                                       | 14/193 [00:00<00:07, 25.46it/s]\u001b[A\n",
      "  9%|███▋                                      | 17/193 [00:00<00:06, 25.48it/s]\u001b[A\n",
      " 10%|████▎                                     | 20/193 [00:00<00:07, 24.08it/s]\u001b[A\n",
      " 12%|█████                                     | 23/193 [00:00<00:06, 24.36it/s]\u001b[A\n",
      " 13%|█████▋                                    | 26/193 [00:01<00:06, 24.83it/s]\u001b[A\n",
      " 15%|██████▎                                   | 29/193 [00:01<00:06, 25.20it/s]\u001b[A\n",
      " 17%|██████▉                                   | 32/193 [00:01<00:06, 25.45it/s]\u001b[A\n",
      " 18%|███████▌                                  | 35/193 [00:01<00:06, 25.98it/s]\u001b[A\n",
      " 20%|████████▎                                 | 38/193 [00:01<00:05, 26.00it/s]\u001b[A\n",
      " 21%|████████▉                                 | 41/193 [00:01<00:05, 25.68it/s]\u001b[A\n",
      " 23%|█████████▌                                | 44/193 [00:01<00:06, 23.93it/s]\u001b[A\n",
      " 24%|██████████▏                               | 47/193 [00:01<00:05, 24.71it/s]\u001b[A\n",
      " 26%|██████████▉                               | 50/193 [00:01<00:05, 24.95it/s]\u001b[A\n",
      " 27%|███████████▌                              | 53/193 [00:02<00:05, 25.19it/s]\u001b[A\n",
      " 29%|████████████▏                             | 56/193 [00:02<00:05, 25.29it/s]\u001b[A\n",
      " 31%|████████████▊                             | 59/193 [00:02<00:05, 25.86it/s]\u001b[A\n",
      " 32%|█████████████▍                            | 62/193 [00:02<00:05, 25.11it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 65/193 [00:02<00:05, 25.30it/s]\u001b[A\n",
      " 35%|██████████████▊                           | 68/193 [00:02<00:05, 24.91it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 71/193 [00:02<00:04, 25.64it/s]\u001b[A\n",
      " 38%|████████████████                          | 74/193 [00:02<00:04, 25.47it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 77/193 [00:03<00:04, 25.54it/s]\u001b[A\n",
      " 41%|█████████████████▍                        | 80/193 [00:03<00:04, 25.47it/s]\u001b[A\n",
      " 43%|██████████████████                        | 83/193 [00:03<00:04, 26.07it/s]\u001b[A\n",
      " 45%|██████████████████▋                       | 86/193 [00:03<00:04, 25.99it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 89/193 [00:03<00:04, 25.33it/s]\u001b[A\n",
      " 48%|████████████████████                      | 92/193 [00:03<00:03, 25.30it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:03<00:03, 25.71it/s]\u001b[A\n",
      " 51%|█████████████████████▎                    | 98/193 [00:03<00:03, 25.67it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:03<00:03, 25.52it/s]\u001b[A\n",
      " 54%|██████████████████████                   | 104/193 [00:04<00:03, 25.45it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 107/193 [00:04<00:03, 25.97it/s]\u001b[A\n",
      " 57%|███████████████████████▎                 | 110/193 [00:04<00:03, 25.97it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:04<00:03, 25.90it/s]\u001b[A\n",
      " 60%|████████████████████████▋                | 116/193 [00:04<00:03, 25.58it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:04<00:02, 26.19it/s]\u001b[A\n",
      " 63%|█████████████████████████▉               | 122/193 [00:04<00:02, 25.53it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:04<00:02, 24.72it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 128/193 [00:05<00:02, 24.46it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:05<00:02, 24.61it/s]\u001b[A\n",
      " 69%|████████████████████████████▍            | 134/193 [00:05<00:02, 24.87it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:05<00:02, 24.95it/s]\u001b[A\n",
      " 73%|█████████████████████████████▋           | 140/193 [00:05<00:02, 25.17it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:05<00:01, 25.74it/s]\u001b[A\n",
      " 76%|███████████████████████████████          | 146/193 [00:05<00:01, 25.48it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:05<00:01, 25.51it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 152/193 [00:05<00:01, 25.55it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:06<00:01, 26.04it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 158/193 [00:06<00:01, 25.87it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:06<00:01, 24.60it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 164/193 [00:06<00:01, 23.99it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:06<00:01, 24.86it/s]\u001b[A\n",
      " 88%|████████████████████████████████████     | 170/193 [00:06<00:00, 24.98it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 173/193 [00:06<00:00, 25.16it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 176/193 [00:06<00:00, 25.29it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 179/193 [00:07<00:00, 25.80it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 182/193 [00:07<00:00, 25.97it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 185/193 [00:07<00:00, 25.37it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 188/193 [00:07<00:00, 25.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.1622869968414307, 'eval_accuracy': 0.6727272868156433, 'eval_runtime': 7.6789, 'eval_samples_per_second': 401.101, 'eval_steps_per_second': 25.134, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 1878/1878 [12:50<00:00, 12.36it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:07<00:00, 25.80it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2039] 2023-04-19 19:42:08,623 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 770.3935, 'train_samples_per_second': 38.953, 'train_steps_per_second': 2.438, 'train_loss': 2.132055378061768, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 1878/1878 [12:50<00:00,  2.44it/s]\n",
      "[INFO|trainer.py:2838] 2023-04-19 19:42:08,632 >> Saving model checkpoint to ./bf16\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     2.1321\n",
      "  train_runtime            = 0:12:50.39\n",
      "  train_samples            =      10003\n",
      "  train_samples_per_second =     38.953\n",
      "  train_steps_per_second   =      2.438\n",
      "[INFO|trainer.py:762] 2023-04-19 19:42:09,642 >> The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainers.py:119] 2023-04-19 19:42:09,643 >> Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "[INFO|trainer.py:3129] 2023-04-19 19:42:09,644 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3131] 2023-04-19 19:42:09,644 >>   Num examples = 3080\n",
      "[INFO|trainer.py:3134] 2023-04-19 19:42:09,644 >>   Batch size = 8\n",
      "100%|█████████████████████████████████████████| 193/193 [00:07<00:00, 25.77it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_accuracy           =     0.6727\n",
      "  eval_loss               =     2.1623\n",
      "  eval_runtime            = 0:00:07.54\n",
      "  eval_samples            =       3080\n",
      "  eval_samples_per_second =    408.153\n",
      "  eval_steps_per_second   =     25.576\n"
     ]
    }
   ],
   "source": [
    "!CUSTOM_CACHE_REPO=philschmid/neuron-cache torchrun --nproc_per_node=2 scripts/run_glue.py  --model_name_or_path bert-base-cased --per_device_train_batch_size 8 --do_train True --do_eval True --bf16 True --dataset_name banking77 --evaluation_strategy \"epoch\" --output_dir ./bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1e1a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "is precompilation: None\n",
      "is precompilation: None\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running training *****\n",
      "  Num examples = 10,003\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1,878\n",
      "  Number of trainable parameters = 109,541,453\n",
      "  0%|                                                  | 0/1878 [00:00<?, ?it/s]2023-04-20 08:32:18.000939: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_16122647675228413938/MODULE_0_SyncTensorsGraph.206_16122647675228413938_ip-172-31-79-164-2386db7d-1329946-5f9bec1877b38/a2267dee-8ec4-4977-ac87-72d7ef644201/MODULE_0_SyncTensorsGraph.206_16122647675228413938_ip-172-31-79-164-2386db7d-1329946-5f9bec1877b38.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "Fetching 42 files:   0%|                                 | 0/42 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Downloading (…)59/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bfa3c9fc64.neff: 100%|█| 8.24k/8.24k [00:00<00:00, 2.02MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bfa3c9fc64.hlo.pb: 100%|█████| 330/330 [00:00<00:00, 82.3kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf61c6716d.hlo.pb:   0%|          | 0.00/1.10M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf61c6716d.neff:   0%|          | 0.00/24.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf7fa98d8f.neff:   0%|          | 0.00/5.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf7fa98d8f.hlo.pb: 100%|███| 291k/291k [00:00<00:00, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)5f9bf61c6716d.hlo.pb: 100%|█| 1.10M/1.10M [00:00<00:00, 36.5MB/s]\n",
      "Downloading (…)6-5f9bf7fa98d8f.neff: 100%|██| 5.07M/5.07M [00:00<00:00, 139MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)6c/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf0c3e9d5d.neff: 100%|█| 7.86k/7.86k [00:00<00:00, 3.08MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf0c3e9d5d.hlo.pb: 100%|██████| 326/326 [00:00<00:00, 228kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf8436afa6.hlo.pb:   0%|           | 0.00/788k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf8436afa6.hlo.pb: 100%|███| 788k/788k [00:00<00:00, 40.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf8436afa6.neff:   0%|          | 0.00/23.1M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)ad/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf61c6716d.neff: 100%|██| 24.5M/24.5M [00:00<00:00, 176MB/s]\n",
      "\n",
      "Fetching 42 files:  10%|██▍                      | 4/42 [00:00<00:02, 17.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf9edacf04.neff: 100%|███| 117k/117k [00:00<00:00, 15.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5b/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf9edacf04.hlo.pb: 100%|█| 71.6k/71.6k [00:00<00:00, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bec1877b38.hlo.pb: 100%|█| 40.6k/40.6k [00:00<00:00, 9.26MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bfa3c9fc64.neff:   0%|          | 0.00/8.24k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bfa3c9fc64.neff: 100%|██| 8.24k/8.24k [00:00<00:00, 646kB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf61c6716d.hlo.pb:   0%|          | 0.00/1.10M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bf8436afa6.neff: 100%|██| 23.1M/23.1M [00:00<00:00, 214MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bfa3c9fc64.hlo.pb:   0%|            | 0.00/330 [00:00<?, ?B/s]\n",
      "\n",
      "Downloading (…)5f9bf3f8edcdc.hlo.pb:   0%|          | 0.00/1.20M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bec1877b38.neff:   0%|           | 0.00/170k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf7fa98d8f.neff:   0%|          | 0.00/5.07M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bfa3c9fc64.hlo.pb: 100%|█████| 330/330 [00:00<00:00, 33.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bec1877b38.neff: 100%|███| 170k/170k [00:00<00:00, 15.1MB/s]\n",
      "Downloading (…)6c/compile_flags.txt: 0.00B [00:00, ?B/s]\n",
      "Downloading (…)5f9bf3f8edcdc.hlo.pb: 100%|█| 1.20M/1.20M [00:00<00:00, 63.1MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf7fa98d8f.hlo.pb: 100%|███| 291k/291k [00:00<00:00, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)5f9bf61c6716d.hlo.pb: 100%|█| 1.10M/1.10M [00:00<00:00, 22.8MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf7fa98d8f.neff: 100%|█| 5.07M/5.07M [00:00<00:00, 89.6MB/s]\n",
      "Downloading (…)19/compile_flags.txt: 0.00B [00:00, ?B/s]\n",
      "\n",
      "Fetching 42 files:  26%|██████▎                 | 11/42 [00:00<00:00, 31.64it/s]\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf0c64fa8d.hlo.pb: 100%|██████| 959/959 [00:00<00:00, 507kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf0c64fa8d.neff: 100%|█| 27.8k/27.8k [00:00<00:00, 5.28MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bf0c3e9d5d.neff: 100%|█| 7.86k/7.86k [00:00<00:00, 4.59MB/s]\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf0c3e9d5d.hlo.pb: 100%|█████| 326/326 [00:00<00:00, 91.3kB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)01/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)01/compile_flags.txt: 0.00B [00:00, ?B/s]\n",
      "Downloading (…)5f9bf8436afa6.hlo.pb:   0%|           | 0.00/788k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf3f8edcdc.neff: 100%|██| 25.7M/25.7M [00:00<00:00, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf8436afa6.neff:   0%|          | 0.00/23.1M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf0c900cfe.hlo.pb: 100%|██████| 401/401 [00:00<00:00, 252kB/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf3f8edcdc.neff: 100%|██| 25.7M/25.7M [00:00<00:00, 227MB/s]\n",
      "Downloading (…)5f9bf8436afa6.hlo.pb: 100%|███| 788k/788k [00:00<00:00, 51.1MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf61c6716d.neff:  86%|█▋| 21.0M/24.5M [00:00<00:00, 128MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)59/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Fetching 42 files:   5%|█▏                       | 2/42 [00:00<00:04,  8.39it/s]\n",
      "\n",
      "Downloading (…)6-5f9bee10df48c.neff:   0%|          | 0.00/26.3M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf0c900cfe.neff: 100%|█| 8.20k/8.20k [00:00<00:00, 5.16MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf61c6716d.neff: 100%|██| 24.5M/24.5M [00:00<00:00, 128MB/s]\n",
      "\n",
      "Downloading (…)6-5f9bf9edacf04.neff: 100%|███| 117k/117k [00:00<00:00, 23.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bee10df48c.hlo.pb:   0%|          | 0.00/1.33M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)0a/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)5f9bee10df48c.hlo.pb: 100%|█| 1.33M/1.33M [00:00<00:00, 59.0MB/s]\u001b[A\n",
      "Downloading (…)5f9bf9edacf04.hlo.pb: 100%|█| 71.6k/71.6k [00:00<00:00, 14.8MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf244eed90.neff:   0%|          | 0.00/23.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf8436afa6.neff:  91%|█▊| 21.0M/23.1M [00:00<00:00, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf8436afa6.neff: 100%|██| 23.1M/23.1M [00:00<00:00, 180MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bec1877b38.hlo.pb: 100%|█| 40.6k/40.6k [00:00<00:00, 4.43MB/s]\n",
      "Downloading (…)5b/compile_flags.txt: 0.00B [00:00, ?B/s]\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bee10df48c.neff: 100%|██| 26.3M/26.3M [00:00<00:00, 253MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf244eed90.hlo.pb:   0%|           | 0.00/788k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bee10df48c.neff: 100%|██| 26.3M/26.3M [00:00<00:00, 243MB/s]\u001b[A\n",
      "Downloading (…)6-5f9bec1877b38.neff: 100%|███| 170k/170k [00:00<00:00, 31.4MB/s]\n",
      "Downloading (…)5f9bf244eed90.hlo.pb: 100%|███| 788k/788k [00:00<00:00, 69.8MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)c1/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bec207772c.neff:   0%|          | 0.00/24.3M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf3f8edcdc.neff:   0%|          | 0.00/25.7M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf3f8edcdc.hlo.pb:   0%|          | 0.00/1.20M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf244eed90.neff: 100%|██| 23.2M/23.2M [00:00<00:00, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf3f8edcdc.hlo.pb: 100%|█| 1.20M/1.20M [00:00<00:00, 83.2MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)01/compile_flags.txt: 0.00B [00:00, ?B/s]00/27.8k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf0c64fa8d.neff: 100%|█| 27.8k/27.8k [00:00<00:00, 9.21MB/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)5f9bec207772c.hlo.pb: 100%|██| 1.26M/1.26M [00:00<00:00, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)15/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading (…)15/compile_flags.txt: 0.00B [00:00, ?B/s]00/5.21M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf0c64fa8d.hlo.pb: 100%|██████| 959/959 [00:00<00:00, 533kB/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bec207772c.neff: 100%|██| 24.3M/24.3M [00:00<00:00, 289MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf0c900cfe.hlo.pb: 100%|██████| 401/401 [00:00<00:00, 246kB/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bf9f5fc6cf.neff: 100%|██| 5.21M/5.21M [00:00<00:00, 176MB/s]\n",
      "\n",
      "Downloading (…)6-5f9bf3f8edcdc.neff: 100%|██| 25.7M/25.7M [00:00<00:00, 232MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)c0/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bf9f5fc6cf.hlo.pb: 100%|███| 207k/207k [00:00<00:00, 61.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bf0c900cfe.neff: 100%|█| 8.20k/8.20k [00:00<00:00, 6.49MB/s]\u001b[A\n",
      "\n",
      "Downloading (…)ad/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Fetching 42 files:  21%|█████▎                   | 9/42 [00:00<00:01, 16.96it/s]\n",
      "Downloading (…)6-5f9bee10df48c.neff:   0%|          | 0.00/26.3M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)86/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)b9/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)5f9bee10df48c.hlo.pb: 100%|█| 1.33M/1.33M [00:00<00:00, 84.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)fa/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)fa/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)0a/compile_flags.txt: 0.00B [00:00, ?B/s][00:00<00:01, 15.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bee10df48c.neff: 100%|██| 26.3M/26.3M [00:00<00:00, 268MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)c1/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)5f9bf244eed90.hlo.pb: 100%|███| 788k/788k [00:00<00:00, 75.8MB/s]\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bec207772c.neff:   0%|          | 0.00/24.3M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)19/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "Fetching 42 files:  26%|██████▎                 | 11/42 [00:00<00:02, 14.98it/s]\n",
      "\n",
      "\n",
      "Downloading (…)5f9bec207772c.hlo.pb: 100%|█| 1.26M/1.26M [00:00<00:00, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf244eed90.neff: 100%|██| 23.2M/23.2M [00:00<00:00, 206MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)c0/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)6-5f9bf9f5fc6cf.neff:   0%|          | 0.00/5.21M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)6-5f9bec207772c.neff: 100%|██| 24.3M/24.3M [00:00<00:00, 238MB/s]\u001b[A\n",
      "\n",
      "Downloading (…)6-5f9bf9f5fc6cf.neff: 100%|██| 5.21M/5.21M [00:00<00:00, 122MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)b1/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)5f9bf9f5fc6cf.hlo.pb: 100%|███| 207k/207k [00:00<00:00, 25.1MB/s]\n",
      "\n",
      "Downloading (…)fa/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Fetching 42 files:  36%|████████▌               | 15/42 [00:00<00:01, 18.15it/s]\n",
      "\n",
      "Downloading (…)b1/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)b9/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Fetching 42 files: 100%|████████████████████████| 42/42 [00:01<00:00, 33.82it/s]\u001b[A\n",
      "\n",
      "Downloading (…)86/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Fetching 42 files:  71%|█████████████████▏      | 30/42 [00:01<00:00, 40.58it/s]\n",
      "Downloading (…)15/compile_flags.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Fetching 42 files: 100%|████████████████████████| 42/42 [00:01<00:00, 37.08it/s]\n",
      "  0%|                                        | 1/1878 [00:04<2:35:42,  4.98s/it]2023-04-20 08:32:24.000861: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_6980420678662761958/MODULE_1_SyncTensorsGraph.22305_6980420678662761958_ip-172-31-79-164-2386db7d-1329946-5f9bec207772c/27132dc7-5d56-4ace-95bd-e52876e46ec0/MODULE_1_SyncTensorsGraph.22305_6980420678662761958_ip-172-31-79-164-2386db7d-1329946-5f9bec207772c.neff. Exiting with a successfully compiled graph\n",
      "2023-Apr-20 08:32:25.0739 1416321:1416335 [0] ofi_init:1453 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2023-Apr-20 08:32:25.0739 1416321:1416335 [0] init.cc:101 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "  0%|                                        | 2/1878 [00:06<1:40:24,  3.21s/it]2023-04-20 08:32:39.000108: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_4678114610732129836/MODULE_2_SyncTensorsGraph.22305_4678114610732129836_ip-172-31-79-164-4ddaa2e-1329946-5f9bee10df48c/1356129f-1a26-4782-b15b-7578721fddc1/MODULE_2_SyncTensorsGraph.22305_4678114610732129836_ip-172-31-79-164-4ddaa2e-1329946-5f9bee10df48c.neff. Exiting with a successfully compiled graph\n",
      " 27%|██████████▋                             | 500/1878 [02:37<05:44,  4.00it/s]2023-04-20 08:34:56.000369: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags ''\n",
      "2023-04-20 08:34:56.000371: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_13378262660058097712/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-b43c9ad1-1329946-5f9bf0c3e9d5d/8285e435-487b-44ec-90a0-e5b1144b0719/MODULE_3_SyncTensorsGraph.4_13378262660058097712_ip-172-31-79-164-b43c9ad1-1329946-5f9bf0c3e9d5d.neff. Exiting with a successfully compiled graph\n",
      "2023-04-20 08:34:56.000448: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_2772047268733908988/MODULE_4_SyncTensorsGraph.21_2772047268733908988_ip-172-31-79-164-4ddaa2e-1329946-5f9bf0c64fa8d/3a2936ad-11db-4d44-9f6c-a9e81cd2e3b9/MODULE_4_SyncTensorsGraph.21_2772047268733908988_ip-172-31-79-164-4ddaa2e-1329946-5f9bf0c64fa8d.neff. Exiting with a successfully compiled graph\n",
      "{'loss': 3.0939, 'learning_rate': 2.2012779552715656e-05, 'epoch': 0.8}         \n",
      " 27%|██████████▋                             | 500/1878 [02:37<05:44,  4.00it/s]2023-04-20 08:34:56.000616: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_3455400400948827543/MODULE_5_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-d6bcfd91-1329946-5f9bf0c900cfe/fd5ae399-772d-4785-99c6-54c4473ae786/MODULE_5_SyncTensorsGraph.6_3455400400948827543_ip-172-31-79-164-d6bcfd91-1329946-5f9bf0c900cfe.neff. Exiting with a successfully compiled graph\n",
      " 33%|█████████████▎                          | 626/1878 [03:08<05:07,  4.08it/s]Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 8\n",
      "2023-04-20 08:35:27.000861: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_7217610760572606364/MODULE_12_SyncTensorsGraph.4547_7217610760572606364_ip-172-31-79-164-f6db173-1329946-5f9bf9f5fc6cf/5ce570ef-8057-4efe-a3d1-8c6d9a41e3b1/MODULE_12_SyncTensorsGraph.4547_7217610760572606364_ip-172-31-79-164-f6db173-1329946-5f9bf9f5fc6cf.neff. Exiting with a successfully compiled graph\n",
      "2023-04-20 08:35:28.000980: INFO ||NCC_WRAPPER||: failed to find a neff compiled with flags ''\n",
      "2023-04-20 08:35:28.000982: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_1002868706066901398/MODULE_13_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-d8d30c9f-1329946-5f9bfa3c9fc64/9a669364-928c-49df-805b-274930929f59/MODULE_13_SyncTensorsGraph.4_1002868706066901398_ip-172-31-79-164-d8d30c9f-1329946-5f9bfa3c9fc64.neff. Exiting with a successfully compiled graph\n",
      "2023-04-20 08:35:29.000063: INFO ||NCC_WRAPPER||: Using a cached neff at /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_14019065114978382472/MODULE_8_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-dfdb1411-1925-5f9b0ccdd1999/1f482008-402e-4360-9218-0242bc4049f0/MODULE_8_SyncTensorsGraph.4_14019065114978382472_ip-172-31-79-164-dfdb1411-1925-5f9b0ccdd1999.neff. Exiting with a successfully compiled graph\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▋                                          | 3/193 [00:00<00:11, 16.88it/s]\u001b[A\n",
      "  3%|█                                          | 5/193 [00:00<00:13, 13.52it/s]\u001b[A\n",
      "  4%|█▌                                         | 7/193 [00:00<00:15, 12.30it/s]\u001b[A\n",
      "  5%|██                                         | 9/193 [00:00<00:15, 11.85it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/193 [00:00<00:15, 11.83it/s]\u001b[A\n",
      "  7%|██▊                                       | 13/193 [00:01<00:15, 11.75it/s]\u001b[A\n",
      "  8%|███▎                                      | 15/193 [00:01<00:15, 11.82it/s]\u001b[A\n",
      "  9%|███▋                                      | 17/193 [00:01<00:15, 11.71it/s]\u001b[A\n",
      " 10%|████▏                                     | 19/193 [00:01<00:14, 11.77it/s]\u001b[A\n",
      " 11%|████▌                                     | 21/193 [00:01<00:14, 11.71it/s]\u001b[A\n",
      " 12%|█████                                     | 23/193 [00:01<00:14, 11.78it/s]\u001b[A\n",
      " 13%|█████▍                                    | 25/193 [00:02<00:14, 11.65it/s]\u001b[A\n",
      " 14%|█████▉                                    | 27/193 [00:02<00:14, 11.75it/s]\u001b[A\n",
      " 15%|██████▎                                   | 29/193 [00:02<00:14, 11.68it/s]\u001b[A\n",
      " 16%|██████▋                                   | 31/193 [00:02<00:13, 11.75it/s]\u001b[A\n",
      " 17%|███████▏                                  | 33/193 [00:02<00:13, 11.68it/s]\u001b[A\n",
      " 18%|███████▌                                  | 35/193 [00:02<00:13, 11.75it/s]\u001b[A\n",
      " 19%|████████                                  | 37/193 [00:03<00:13, 11.64it/s]\u001b[A\n",
      " 20%|████████▍                                 | 39/193 [00:03<00:13, 11.72it/s]\u001b[A\n",
      " 21%|████████▉                                 | 41/193 [00:03<00:13, 11.53it/s]\u001b[A\n",
      " 22%|█████████▎                                | 43/193 [00:03<00:13, 11.42it/s]\u001b[A\n",
      " 23%|█████████▊                                | 45/193 [00:03<00:13, 11.34it/s]\u001b[A\n",
      " 24%|██████████▏                               | 47/193 [00:03<00:12, 11.52it/s]\u001b[A\n",
      " 25%|██████████▋                               | 49/193 [00:04<00:12, 11.45it/s]\u001b[A\n",
      " 26%|███████████                               | 51/193 [00:04<00:12, 11.54it/s]\u001b[A\n",
      " 27%|███████████▌                              | 53/193 [00:04<00:12, 11.56it/s]\u001b[A\n",
      " 28%|███████████▉                              | 55/193 [00:04<00:11, 11.62it/s]\u001b[A\n",
      " 30%|████████████▍                             | 57/193 [00:04<00:11, 11.49it/s]\u001b[A\n",
      " 31%|████████████▊                             | 59/193 [00:05<00:11, 11.31it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 61/193 [00:05<00:11, 11.33it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 63/193 [00:05<00:11, 11.48it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 65/193 [00:05<00:11, 11.39it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 67/193 [00:05<00:10, 11.54it/s]\u001b[A\n",
      " 36%|███████████████                           | 69/193 [00:05<00:10, 11.55it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 71/193 [00:06<00:10, 11.44it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 73/193 [00:06<00:10, 11.49it/s]\u001b[A\n",
      " 39%|████████████████▎                         | 75/193 [00:06<00:10, 11.60it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 77/193 [00:06<00:10, 11.23it/s]\u001b[A\n",
      " 41%|█████████████████▏                        | 79/193 [00:06<00:10, 11.39it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 81/193 [00:06<00:09, 11.46it/s]\u001b[A\n",
      " 43%|██████████████████                        | 83/193 [00:07<00:09, 11.38it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 85/193 [00:07<00:09, 11.39it/s]\u001b[A\n",
      " 45%|██████████████████▉                       | 87/193 [00:07<00:09, 11.30it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 89/193 [00:07<00:09, 11.34it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 91/193 [00:07<00:08, 11.49it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 93/193 [00:08<00:08, 11.48it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:08<00:08, 11.48it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 97/193 [00:08<00:08, 11.48it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 99/193 [00:08<00:08, 11.61it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:08<00:07, 11.58it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 103/193 [00:08<00:07, 11.67it/s]\u001b[A\n",
      " 54%|██████████████████████▎                  | 105/193 [00:09<00:07, 11.49it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 107/193 [00:09<00:07, 11.19it/s]\u001b[A\n",
      " 56%|███████████████████████▏                 | 109/193 [00:09<00:07, 11.29it/s]\u001b[A\n",
      " 58%|███████████████████████▌                 | 111/193 [00:09<00:07, 11.47it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:09<00:07, 11.27it/s]\u001b[A\n",
      " 60%|████████████████████████▍                | 115/193 [00:09<00:06, 11.40it/s]\u001b[A\n",
      " 61%|████████████████████████▊                | 117/193 [00:10<00:06, 11.44it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:10<00:06, 11.56it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 121/193 [00:10<00:06, 11.51it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 123/193 [00:10<00:06, 11.64it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:10<00:05, 11.56it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 127/193 [00:10<00:05, 11.64it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 129/193 [00:11<00:05, 11.16it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:11<00:05, 10.96it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 133/193 [00:11<00:05, 10.93it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 135/193 [00:11<00:05, 11.22it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:11<00:04, 11.24it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 139/193 [00:12<00:04, 11.41it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 141/193 [00:12<00:04, 11.46it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:12<00:04, 11.58it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 145/193 [00:12<00:04, 11.50it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 147/193 [00:12<00:03, 11.64it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:12<00:03, 11.49it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 151/193 [00:13<00:03, 11.62it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 153/193 [00:13<00:03, 11.57it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:13<00:03, 11.47it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 157/193 [00:13<00:03, 11.40it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 159/193 [00:13<00:02, 11.56it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:13<00:02, 11.51it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 163/193 [00:14<00:02, 11.61it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 165/193 [00:14<00:02, 11.61it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:14<00:02, 11.69it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 169/193 [00:14<00:02, 11.66it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 171/193 [00:14<00:01, 11.61it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 173/193 [00:14<00:01, 11.53it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 175/193 [00:15<00:01, 11.61it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 177/193 [00:15<00:01, 11.61it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 179/193 [00:15<00:01, 11.70it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 181/193 [00:15<00:01, 11.73it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 183/193 [00:15<00:00, 11.78it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 185/193 [00:16<00:00, 11.61it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 187/193 [00:16<00:00, 11.54it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 189/193 [00:16<00:00, 11.40it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 191/193 [00:16<00:00, 11.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.4122501611709595, 'eval_f1': 0.7667163223135263, 'eval_runtime': 18.2233, 'eval_samples_per_second': 169.015, 'eval_steps_per_second': 10.591, 'epoch': 1.0}\n",
      " 33%|█████████████▎                          | 626/1878 [03:27<05:07,  4.08it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:16<00:00, 11.66it/s]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to run1/checkpoint-626\n",
      "Deleting older checkpoint [run1/checkpoint-1252] due to args.save_total_limit\n",
      "{'loss': 1.2073, 'learning_rate': 1.402555910543131e-05, 'epoch': 1.6}          \n",
      " 67%|██████████████████████████             | 1252/1878 [06:06<02:34,  4.04it/s]Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▋                                          | 3/193 [00:00<00:10, 17.50it/s]\u001b[A\n",
      "  3%|█                                          | 5/193 [00:00<00:13, 13.88it/s]\u001b[A\n",
      "  4%|█▌                                         | 7/193 [00:00<00:14, 12.80it/s]\u001b[A\n",
      "  5%|██                                         | 9/193 [00:00<00:15, 12.25it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/193 [00:00<00:15, 12.13it/s]\u001b[A\n",
      "  7%|██▊                                       | 13/193 [00:01<00:15, 11.93it/s]\u001b[A\n",
      "  8%|███▎                                      | 15/193 [00:01<00:16, 10.74it/s]\u001b[A\n",
      "  9%|███▋                                      | 17/193 [00:01<00:16, 10.86it/s]\u001b[A\n",
      " 10%|████▏                                     | 19/193 [00:01<00:15, 11.12it/s]\u001b[A\n",
      " 11%|████▌                                     | 21/193 [00:01<00:15, 11.07it/s]\u001b[A\n",
      " 12%|█████                                     | 23/193 [00:01<00:15, 11.28it/s]\u001b[A\n",
      " 13%|█████▍                                    | 25/193 [00:02<00:14, 11.33it/s]\u001b[A\n",
      " 14%|█████▉                                    | 27/193 [00:02<00:14, 11.51it/s]\u001b[A\n",
      " 15%|██████▎                                   | 29/193 [00:02<00:14, 11.48it/s]\u001b[A\n",
      " 16%|██████▋                                   | 31/193 [00:02<00:14, 11.19it/s]\u001b[A\n",
      " 17%|███████▏                                  | 33/193 [00:02<00:14, 11.27it/s]\u001b[A\n",
      " 18%|███████▌                                  | 35/193 [00:03<00:14, 11.25it/s]\u001b[A\n",
      " 19%|████████                                  | 37/193 [00:03<00:13, 11.30it/s]\u001b[A\n",
      " 20%|████████▍                                 | 39/193 [00:03<00:13, 11.48it/s]\u001b[A\n",
      " 21%|████████▉                                 | 41/193 [00:03<00:13, 11.22it/s]\u001b[A\n",
      " 22%|█████████▎                                | 43/193 [00:03<00:13, 11.02it/s]\u001b[A\n",
      " 23%|█████████▊                                | 45/193 [00:03<00:13, 11.16it/s]\u001b[A\n",
      " 24%|██████████▏                               | 47/193 [00:04<00:12, 11.24it/s]\u001b[A\n",
      " 25%|██████████▋                               | 49/193 [00:04<00:12, 11.33it/s]\u001b[A\n",
      " 26%|███████████                               | 51/193 [00:04<00:12, 11.50it/s]\u001b[A\n",
      " 27%|███████████▌                              | 53/193 [00:04<00:12, 11.51it/s]\u001b[A\n",
      " 28%|███████████▉                              | 55/193 [00:04<00:11, 11.62it/s]\u001b[A\n",
      " 30%|████████████▍                             | 57/193 [00:04<00:11, 11.59it/s]\u001b[A\n",
      " 31%|████████████▊                             | 59/193 [00:05<00:11, 11.48it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 61/193 [00:05<00:11, 11.46it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 63/193 [00:05<00:11, 11.46it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 65/193 [00:05<00:11, 11.37it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 67/193 [00:05<00:10, 11.51it/s]\u001b[A\n",
      " 36%|███████████████                           | 69/193 [00:05<00:10, 11.52it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 71/193 [00:06<00:10, 11.26it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 73/193 [00:06<00:10, 11.30it/s]\u001b[A\n",
      " 39%|████████████████▎                         | 75/193 [00:06<00:10, 11.48it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 77/193 [00:06<00:10, 11.31it/s]\u001b[A\n",
      " 41%|█████████████████▏                        | 79/193 [00:06<00:10, 11.29it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 81/193 [00:07<00:10, 11.16it/s]\u001b[A\n",
      " 43%|██████████████████                        | 83/193 [00:07<00:10, 10.99it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 85/193 [00:07<00:09, 11.16it/s]\u001b[A\n",
      " 45%|██████████████████▉                       | 87/193 [00:07<00:09, 11.39it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 89/193 [00:07<00:09, 11.46it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 91/193 [00:07<00:08, 11.39it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 93/193 [00:08<00:08, 11.42it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:08<00:08, 11.52it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 97/193 [00:08<00:08, 11.40it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 99/193 [00:08<00:08, 11.29it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:08<00:08, 11.34it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 103/193 [00:08<00:07, 11.52it/s]\u001b[A\n",
      " 54%|██████████████████████▎                  | 105/193 [00:09<00:07, 11.41it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 107/193 [00:09<00:07, 11.53it/s]\u001b[A\n",
      " 56%|███████████████████████▏                 | 109/193 [00:09<00:07, 11.50it/s]\u001b[A\n",
      " 58%|███████████████████████▌                 | 111/193 [00:09<00:07, 11.48it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:09<00:07, 11.42it/s]\u001b[A\n",
      " 60%|████████████████████████▍                | 115/193 [00:10<00:06, 11.56it/s]\u001b[A\n",
      " 61%|████████████████████████▊                | 117/193 [00:10<00:06, 11.56it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:10<00:06, 11.40it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 121/193 [00:10<00:06, 11.26it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 123/193 [00:10<00:06, 11.04it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:10<00:06, 11.20it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 127/193 [00:11<00:05, 11.20it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 129/193 [00:11<00:05, 11.26it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:11<00:05, 11.25it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 133/193 [00:11<00:05, 11.26it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 135/193 [00:11<00:05, 11.45it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:11<00:04, 11.47it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 139/193 [00:12<00:04, 11.59it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 141/193 [00:12<00:04, 11.56it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:12<00:04, 11.67it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 145/193 [00:12<00:04, 11.55it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 147/193 [00:12<00:04, 11.49it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:13<00:03, 11.45it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 151/193 [00:13<00:03, 11.38it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 153/193 [00:13<00:03, 11.31it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:13<00:03, 11.48it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 157/193 [00:13<00:03, 11.49it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 159/193 [00:13<00:02, 11.60it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:14<00:02, 11.46it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 163/193 [00:14<00:02, 11.58it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 165/193 [00:14<00:02, 11.57it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:14<00:02, 11.65it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 169/193 [00:14<00:02, 11.37it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 171/193 [00:14<00:01, 11.31it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 173/193 [00:15<00:01, 11.37it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 175/193 [00:15<00:01, 11.21it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 177/193 [00:15<00:01, 11.27it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 179/193 [00:15<00:01, 11.21it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 181/193 [00:15<00:01, 11.16it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 183/193 [00:16<00:00, 11.34it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 185/193 [00:16<00:00, 11.43it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 187/193 [00:16<00:00, 11.35it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 189/193 [00:16<00:00, 11.48it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 191/193 [00:16<00:00, 11.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6288191676139832, 'eval_f1': 0.8866345562609093, 'eval_runtime': 17.0679, 'eval_samples_per_second': 180.456, 'eval_steps_per_second': 11.308, 'epoch': 2.0}\n",
      " 67%|██████████████████████████             | 1252/1878 [06:24<02:34,  4.04it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:16<00:00, 11.49it/s]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to run1/checkpoint-1252\n",
      "Deleting older checkpoint [run1/checkpoint-1878] due to args.save_total_limit\n",
      "{'loss': 0.596, 'learning_rate': 6.038338658146965e-06, 'epoch': 2.4}           \n",
      "100%|███████████████████████████████████████| 1878/1878 [09:03<00:00,  4.07it/s]Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 8\n",
      "\n",
      "  0%|                                                   | 0/193 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▋                                          | 3/193 [00:00<00:11, 16.86it/s]\u001b[A\n",
      "  3%|█                                          | 5/193 [00:00<00:14, 13.31it/s]\u001b[A\n",
      "  4%|█▌                                         | 7/193 [00:00<00:15, 12.32it/s]\u001b[A\n",
      "  5%|██                                         | 9/193 [00:00<00:15, 12.00it/s]\u001b[A\n",
      "  6%|██▍                                       | 11/193 [00:00<00:15, 11.91it/s]\u001b[A\n",
      "  7%|██▊                                       | 13/193 [00:01<00:15, 11.82it/s]\u001b[A\n",
      "  8%|███▎                                      | 15/193 [00:01<00:15, 11.83it/s]\u001b[A\n",
      "  9%|███▋                                      | 17/193 [00:01<00:15, 11.71it/s]\u001b[A\n",
      " 10%|████▏                                     | 19/193 [00:01<00:14, 11.75it/s]\u001b[A\n",
      " 11%|████▌                                     | 21/193 [00:01<00:14, 11.66it/s]\u001b[A\n",
      " 12%|█████                                     | 23/193 [00:01<00:14, 11.69it/s]\u001b[A\n",
      " 13%|█████▍                                    | 25/193 [00:02<00:14, 11.35it/s]\u001b[A\n",
      " 14%|█████▉                                    | 27/193 [00:02<00:14, 11.48it/s]\u001b[A\n",
      " 15%|██████▎                                   | 29/193 [00:02<00:14, 11.50it/s]\u001b[A\n",
      " 16%|██████▋                                   | 31/193 [00:02<00:13, 11.62it/s]\u001b[A\n",
      " 17%|███████▏                                  | 33/193 [00:02<00:13, 11.54it/s]\u001b[A\n",
      " 18%|███████▌                                  | 35/193 [00:02<00:13, 11.67it/s]\u001b[A\n",
      " 19%|████████                                  | 37/193 [00:03<00:13, 11.57it/s]\u001b[A\n",
      " 20%|████████▍                                 | 39/193 [00:03<00:13, 11.59it/s]\u001b[A\n",
      " 21%|████████▉                                 | 41/193 [00:03<00:13, 11.51it/s]\u001b[A\n",
      " 22%|█████████▎                                | 43/193 [00:03<00:12, 11.62it/s]\u001b[A\n",
      " 23%|█████████▊                                | 45/193 [00:03<00:13, 11.31it/s]\u001b[A\n",
      " 24%|██████████▏                               | 47/193 [00:04<00:12, 11.24it/s]\u001b[A\n",
      " 25%|██████████▋                               | 49/193 [00:04<00:12, 11.27it/s]\u001b[A\n",
      " 26%|███████████                               | 51/193 [00:04<00:12, 11.45it/s]\u001b[A\n",
      " 27%|███████████▌                              | 53/193 [00:04<00:12, 11.46it/s]\u001b[A\n",
      " 28%|███████████▉                              | 55/193 [00:04<00:11, 11.59it/s]\u001b[A\n",
      " 30%|████████████▍                             | 57/193 [00:04<00:11, 11.58it/s]\u001b[A\n",
      " 31%|████████████▊                             | 59/193 [00:05<00:11, 11.65it/s]\u001b[A\n",
      " 32%|█████████████▎                            | 61/193 [00:05<00:11, 11.58it/s]\u001b[A\n",
      " 33%|█████████████▋                            | 63/193 [00:05<00:11, 11.65it/s]\u001b[A\n",
      " 34%|██████████████▏                           | 65/193 [00:05<00:11, 11.63it/s]\u001b[A\n",
      " 35%|██████████████▌                           | 67/193 [00:05<00:10, 11.71it/s]\u001b[A\n",
      " 36%|███████████████                           | 69/193 [00:05<00:10, 11.40it/s]\u001b[A\n",
      " 37%|███████████████▍                          | 71/193 [00:06<00:10, 11.34it/s]\u001b[A\n",
      " 38%|███████████████▉                          | 73/193 [00:06<00:10, 11.42it/s]\u001b[A\n",
      " 39%|████████████████▎                         | 75/193 [00:06<00:10, 11.53it/s]\u001b[A\n",
      " 40%|████████████████▊                         | 77/193 [00:06<00:10, 11.52it/s]\u001b[A\n",
      " 41%|█████████████████▏                        | 79/193 [00:06<00:09, 11.62it/s]\u001b[A\n",
      " 42%|█████████████████▋                        | 81/193 [00:06<00:09, 11.62it/s]\u001b[A\n",
      " 43%|██████████████████                        | 83/193 [00:07<00:09, 11.71it/s]\u001b[A\n",
      " 44%|██████████████████▍                       | 85/193 [00:07<00:09, 11.43it/s]\u001b[A\n",
      " 45%|██████████████████▉                       | 87/193 [00:07<00:09, 11.15it/s]\u001b[A\n",
      " 46%|███████████████████▎                      | 89/193 [00:07<00:09, 11.27it/s]\u001b[A\n",
      " 47%|███████████████████▊                      | 91/193 [00:07<00:09, 11.31it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 93/193 [00:08<00:08, 11.39it/s]\u001b[A\n",
      " 49%|████████████████████▋                     | 95/193 [00:08<00:08, 11.54it/s]\u001b[A\n",
      " 50%|█████████████████████                     | 97/193 [00:08<00:08, 11.55it/s]\u001b[A\n",
      " 51%|█████████████████████▌                    | 99/193 [00:08<00:08, 11.63it/s]\u001b[A\n",
      " 52%|█████████████████████▍                   | 101/193 [00:08<00:07, 11.55it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 103/193 [00:08<00:07, 11.41it/s]\u001b[A\n",
      " 54%|██████████████████████▎                  | 105/193 [00:09<00:07, 11.46it/s]\u001b[A\n",
      " 55%|██████████████████████▋                  | 107/193 [00:09<00:07, 11.58it/s]\u001b[A\n",
      " 56%|███████████████████████▏                 | 109/193 [00:09<00:07, 11.54it/s]\u001b[A\n",
      " 58%|███████████████████████▌                 | 111/193 [00:09<00:07, 11.25it/s]\u001b[A\n",
      " 59%|████████████████████████                 | 113/193 [00:09<00:07, 11.22it/s]\u001b[A\n",
      " 60%|████████████████████████▍                | 115/193 [00:09<00:06, 11.38it/s]\u001b[A\n",
      " 61%|████████████████████████▊                | 117/193 [00:10<00:06, 11.09it/s]\u001b[A\n",
      " 62%|█████████████████████████▎               | 119/193 [00:10<00:06, 11.13it/s]\u001b[A\n",
      " 63%|█████████████████████████▋               | 121/193 [00:10<00:06, 11.00it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 123/193 [00:10<00:06, 10.93it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 125/193 [00:10<00:06, 10.97it/s]\u001b[A\n",
      " 66%|██████████████████████████▉              | 127/193 [00:11<00:06, 10.78it/s]\u001b[A\n",
      " 67%|███████████████████████████▍             | 129/193 [00:11<00:05, 10.98it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 131/193 [00:11<00:05, 11.20it/s]\u001b[A\n",
      " 69%|████████████████████████████▎            | 133/193 [00:11<00:05, 11.20it/s]\u001b[A\n",
      " 70%|████████████████████████████▋            | 135/193 [00:11<00:05, 11.39it/s]\u001b[A\n",
      " 71%|█████████████████████████████            | 137/193 [00:11<00:04, 11.41it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 139/193 [00:12<00:04, 11.54it/s]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 141/193 [00:12<00:04, 11.49it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 143/193 [00:12<00:04, 11.61it/s]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 145/193 [00:12<00:04, 11.61it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 147/193 [00:12<00:03, 11.69it/s]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 149/193 [00:12<00:03, 11.65it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 151/193 [00:13<00:03, 11.51it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 153/193 [00:13<00:03, 11.53it/s]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 155/193 [00:13<00:03, 11.63it/s]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 157/193 [00:13<00:03, 11.60it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 159/193 [00:13<00:02, 11.64it/s]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 161/193 [00:13<00:02, 11.58it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 163/193 [00:14<00:02, 11.50it/s]\u001b[A\n",
      " 85%|███████████████████████████████████      | 165/193 [00:14<00:02, 11.50it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 167/193 [00:14<00:02, 11.61it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 169/193 [00:14<00:02, 11.57it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 171/193 [00:14<00:01, 11.67it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 173/193 [00:15<00:01, 11.58it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 175/193 [00:15<00:01, 11.53it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 177/193 [00:15<00:01, 11.53it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 179/193 [00:15<00:01, 11.52it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 181/193 [00:15<00:01, 11.44it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 183/193 [00:15<00:00, 11.56it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 185/193 [00:16<00:00, 11.61it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 187/193 [00:16<00:00, 11.29it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 189/193 [00:16<00:00, 11.17it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 191/193 [00:16<00:00, 11.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.48412078619003296, 'eval_f1': 0.907239137814129, 'eval_runtime': 17.3178, 'eval_samples_per_second': 177.851, 'eval_steps_per_second': 11.145, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 1878/1878 [09:21<00:00,  4.07it/s]\n",
      "100%|█████████████████████████████████████████| 193/193 [00:16<00:00, 11.51it/s]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to run1/checkpoint-1878\n",
      "Deleting older checkpoint [run1/checkpoint-626] due to args.save_total_limit\n",
      "2023-04-20 08:41:45.000779: INFO ||NCC_WRAPPER||: No candidate found under /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12488343762238178016.\n",
      "2023-04-20 08:41:45.000779: INFO ||NCC_WRAPPER||: Cache dir for the neff: /tmp/tmpjb1ix1_v/neuron-compile-cache/USER_neuroncc-2.4.0.21+b7621be18/MODULE_12488343762238178016/MODULE_9_SyncTensorsGraph.31_12488343762238178016_ip-172-31-79-164-d38b4969-1416321-5f9c082b8cfaa/3ce3a1fb-d675-4383-9cde-4615e8a77603\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      ".\n",
      "Compiler status PASS\n",
      "2023-04-20 08:41:48.000356: INFO ||NCC_WRAPPER||: Exiting with a successfully compiled graph\n",
      "{'train_runtime': 567.0056, 'train_samples_per_second': 52.925, 'train_steps_per_second': 3.312, 'train_loss': 1.3892742640421158, 'epoch': 3.0}\n",
      "100%|███████████████████████████████████████| 1878/1878 [09:29<00:00,  3.30it/s]\n",
      "Disabling DDP because it is currently not playing well with multiple workers training, for more information please refer to https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/tutorials/training/finetune_hftrainer.html#multi-worker-training\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 8\n",
      " 99%|████████████████████████████████████████▊| 192/193 [00:17<00:00, 11.83it/s]{'eval_loss': 0.48412078619003296, 'eval_f1': 0.907239137814129, 'eval_runtime': 17.6031, 'eval_samples_per_second': 174.969, 'eval_steps_per_second': 10.964, 'epoch': 3.0}\n",
      "100%|█████████████████████████████████████████| 193/193 [00:17<00:00, 11.00it/s]\n",
      "Upload 1 LFS files:   0%|                                 | 0/1 [00:00<?, ?it/s]\n",
      "MODULE_9_SyncTensorsGraph.31_12488343762238178016_d38b4969-1416321-5f9c082b8cfaa\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████| 1/1 [00:00<00:00,  6.77it/s]\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/huggingface_hub/_commit_api.py:491: UserWarning: About to commit an empty file: '2.4.0.21+b7621be18/bert/b6f2e40b0876f7793c485f387087750e2f07274a52c5e47f8515b9bed168b8429a8408c2f02e7607c32d7ea0fa9c98d972dbc0678619feefa5611d3172bd9cd0/90a9a686ce512edbdc037c4c5d241ac5ed0cecdbd3c770fd181c43e656af84e916e1be1b6a8100dd027b36a0096c666dbafdfc7b6ffc0012a38c5f68ba6c6e04/MODULE_12488343762238178016/MODULE_9_SyncTensorsGraph.31_12488343762238178016_ip-172-31-79-164-d38b4969-1416321-5f9c082b8cfaa/3ce3a1fb-d675-4383-9cde-4615e8a77603/compile_flags.txt'. Are you sure this is intended?\n",
      "  warnings.warn(f\"About to commit an empty file: '{path}'. Are you sure this is intended?\")\n",
      "{'eval_loss': 0.48412078619003296, 'eval_f1': 0.907239137814129, 'eval_runtime': 17.6515, 'eval_samples_per_second': 174.49, 'eval_steps_per_second': 10.934, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "!CUSTOM_CACHE_REPO=philschmid/neuron-cache torchrun --nproc_per_node=2 scripts/train.py --model_id bert-base-uncased --lr 3e-5 --per_device_train_batch_size 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c13e9d9",
   "metadata": {},
   "source": [
    "1760.8812s -> 591.1733s \n",
    "\n",
    "\n",
    "bf16 {'train_runtime': 426.354, 'train_samples_per_second': 70.385, 'train_steps_per_second': 4.405, 'train_loss': 4.362087326943557, 'epoch': 3.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604a4a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2015aaa8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
