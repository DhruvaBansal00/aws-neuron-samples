{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/aws_neuron_venv_pytorch_p37/lib64/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tokenizer and model\n",
    "# model_id = \"yiyanghkust/finbert-tone\"\n",
    "model_id = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "# model_id = \"thusken/nb-bert-large-user-needs\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, torchscript=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy input for max length 128\n",
    "def generate_sample_inputs(tokenizer, *payload, sequence_length=128):\n",
    "  embeddings = tokenizer(*payload, max_length=sequence_length, padding=\"max_length\",return_tensors=\"pt\")\n",
    "  return tuple(embeddings.values())\n",
    "\n",
    "\n",
    "payload = \"i am happy that my stock grew5%.\"\n",
    "neuron_inputs = generate_sample_inputs(tokenizer,payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the original PyTorch model on examples\n",
    "with torch.inference_mode():\n",
    "  reference_logits = model(*neuron_inputs)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2022 03:24:21 PM WARNING 112653 [py.warnings]: /home/ec2-user/aws_neuron_venv_pytorch_p37/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "12/08/2022 03:24:41 PM WARNING 112653 [py.warnings]: /home/ec2-user/aws_neuron_venv_pytorch_p37/bin/neuronx-cc:8: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  sys.exit(main())\n",
      "\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: 100% PSUM demand before spilling\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: spilling from PSUM cost about 3888 cycles\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: 100% PSUM utilization after allocation\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: 0% SB utilization after allocation\n",
      "12/08/2022 03:24:44 PM WARNING 112653 [WalrusDriver]: DRAM allocation successful\n",
      "12/08/2022 03:25:05 PM WARNING 112653 [job.Kelper.0]: writeKelp missing file sg00/nn_def.json\n",
      "12/08/2022 03:25:05 PM WARNING 112653 [job.Kelper.0]: writeKelp missing file sg00/kelf.json\n",
      "12/08/2022 03:25:05 PM WARNING 112653 [job.Kelper.0]: writeKelp missing file sg00/ucode_lib.json\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# use only one neuron core\n",
    "os.environ[\"NEURON_RT_NUM_CORES\"] = \"1\"\n",
    "\n",
    "# Run precompiled TorchScript that is optimized by AWS Neuron Inf2\n",
    "neuron_model = torch_neuronx.trace(model, neuron_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the TorchScript works on both example inputs\n",
    "neuron_logits = neuron_model(*neuron_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Logits:     [[-2.8316336 -0.3366956  3.8156364]]\n",
      "Neuron Logits:        [[-2.8326252  -0.33097273  3.8116004 ]]\n"
     ]
    }
   ],
   "source": [
    "print('Reference Logits:    ', reference_logits.detach().numpy())\n",
    "print('Neuron Logits:       ', neuron_logits.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.001279529184103012},\n",
       " {'label': 'LABEL_1', 'score': 0.015613634139299393},\n",
       " {'label': 'LABEL_2', 'score': 0.9831068515777588}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.nn.Softmax(dim=-1)(neuron_logits)[0]\n",
    "\n",
    "[{\"label\": model.config.id2label[i], \"score\": score.item()} for i, score in enumerate(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('aws_neuron_venv_pytorch_p37': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09196ff524c08030a96c80aa185124b0e278041a4aee2efe3c8cd5d8ec5dcc88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
